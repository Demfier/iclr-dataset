{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import glasbey\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path\n",
    "import distro\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables/iclr24v2\")\n",
    "figures_path = Path(\"../results/figures\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"matplotlib_style.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Rita Gonz치lez-M치rquez\n",
      "\n",
      "Last updated: 2024-03-26 08:28:57CET\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.5\n",
      "IPython version      : 8.18.1\n",
      "\n",
      "transformers: 4.35.2\n",
      "openTSNE    : 1.0.0\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 3.10.0-1160.el7.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 64\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: rgonzalesmarquez_GPU0-llm_gber7\n",
      "\n",
      "numpy          : 1.26.2\n",
      "jupyter_black  : 0.3.4\n",
      "distro         : 1.8.0\n",
      "pandas         : 2.1.3\n",
      "sklearn        : 1.3.2\n",
      "scipy          : 1.11.4\n",
      "matplotlib     : 3.8.2\n",
      "glasbey        : 0.2.0\n",
      "openTSNE       : 1.0.0\n",
      "seaborn        : 0.13.0\n",
      "memory_profiler: 0.61.0\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a 'Rita Gonz치lez-M치rquez' -t -d -tz -u -v -iv -w -m -h -p transformers,openTSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "ICLR new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 185 ms, sys: 59 ms, total: 244 ms\n",
      "Wall time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iclr2024 = pd.read_parquet(\n",
    "    data_path / \"iclr24v2.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr2024.keywords = iclr2024.keywords.transform(lambda x: list(x))\n",
    "iclr2024.scores = iclr2024.scores.transform(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-Hhnslg</td>\n",
       "      <td>Prototypical Networks for Few-shot Learning</td>\n",
       "      <td>A recent approach to few-shot classification c...</td>\n",
       "      <td>Jake Snell, Kevin Swersky, Richard Zemel</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>[deep learning, transfer learning]</td>\n",
       "      <td>transfer learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-q5Pqxl</td>\n",
       "      <td>Machine Comprehension Using Match-LSTM and Ans...</td>\n",
       "      <td>Machine comprehension of text is an important ...</td>\n",
       "      <td>Shuohang Wang, Jing Jiang</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 7]</td>\n",
       "      <td>[natural language processing, deep learning]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16Jem9xe</td>\n",
       "      <td>Learning in Implicit Generative Models</td>\n",
       "      <td>Generative adversarial networks (GANs) provide...</td>\n",
       "      <td>Shakir Mohamed, Balaji Lakshminarayanan</td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[8, 7, 6]</td>\n",
       "      <td>[unsupervised learning]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16dGcqlx</td>\n",
       "      <td>Third Person Imitation Learning</td>\n",
       "      <td>Reinforcement learning (RL) makes it possible ...</td>\n",
       "      <td>Bradly C Stadie, Pieter Abbeel, Ilya Sutskever</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>B184E5qee</td>\n",
       "      <td>Improving Neural Language Models with a Contin...</td>\n",
       "      <td>We propose an extension to neural network lang...</td>\n",
       "      <td>Edouard Grave, Armand Joulin, Nicolas Usunier</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[7, 9, 5]</td>\n",
       "      <td>[natural language processing]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year         id                                              title  \\\n",
       "0  2017  B1-Hhnslg        Prototypical Networks for Few-shot Learning   \n",
       "1  2017  B1-q5Pqxl  Machine Comprehension Using Match-LSTM and Ans...   \n",
       "2  2017  B16Jem9xe             Learning in Implicit Generative Models   \n",
       "3  2017  B16dGcqlx                    Third Person Imitation Learning   \n",
       "4  2017  B184E5qee  Improving Neural Language Models with a Contin...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A recent approach to few-shot classification c...   \n",
       "1  Machine comprehension of text is an important ...   \n",
       "2  Generative adversarial networks (GANs) provide...   \n",
       "3  Reinforcement learning (RL) makes it possible ...   \n",
       "4  We propose an extension to neural network lang...   \n",
       "\n",
       "                                          authors                  decision  \\\n",
       "0        Jake Snell, Kevin Swersky, Richard Zemel                    Reject   \n",
       "1                       Shuohang Wang, Jing Jiang           Accept (Poster)   \n",
       "2         Shakir Mohamed, Balaji Lakshminarayanan  Invite to Workshop Track   \n",
       "3  Bradly C Stadie, Pieter Abbeel, Ilya Sutskever           Accept (Poster)   \n",
       "4   Edouard Grave, Armand Joulin, Nicolas Usunier           Accept (Poster)   \n",
       "\n",
       "      scores                                      keywords             labels  \n",
       "0  [6, 4, 5]            [deep learning, transfer learning]  transfer learning  \n",
       "1  [6, 6, 7]  [natural language processing, deep learning]    language models  \n",
       "2  [8, 7, 6]                       [unsupervised learning]          unlabeled  \n",
       "3  [6, 5, 6]                                            []          unlabeled  \n",
       "4  [7, 9, 5]                 [natural language processing]    language models  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr2024.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists of keywords and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_keywords_groups = [\n",
    "    ###### ADVERSARIAL\n",
    "    [\n",
    "        (\"adversarial\", 60),\n",
    "        (\"adversarial attack\", 121),\n",
    "        (\"adversarial attacks\", 106),\n",
    "        (\"adversarial defense\", 50),\n",
    "        (\"adversarial examples\", 196),\n",
    "        (\"adversarial learning\", 93),\n",
    "        (\"adversarial machine learning\", 54),\n",
    "        (\"adversarial robustness\", 241),\n",
    "        (\"adversarial training\", 217),\n",
    "    ],\n",
    "    ###### TRANSFORMERS\n",
    "    [\n",
    "        (\"attention\", 183),\n",
    "        (\"attention mechanism\", 53),\n",
    "        (\"transformer\", 340),\n",
    "        (\"transformers\", 261),\n",
    "        (\"self-attention\", 73),\n",
    "    ],\n",
    "    ###### AUTOENCODERS\n",
    "    [\n",
    "        (\"autoencoder\", 63),\n",
    "        (\"autoencoders\", 52),\n",
    "        (\"vae\", 71),\n",
    "        (\"variational autoencoder\", 93),\n",
    "        (\"variational autoencoders\", 83),\n",
    "    ],\n",
    "    [(\"anomaly detection\", 109)],\n",
    "    [(\"causal discovery\", 53), (\"causal inference\", 104), (\"causality\", 80)],\n",
    "    [(\"clustering\", 116)],\n",
    "    [(\"compression\", 121), (\"model compression\", 135)],\n",
    "    ###### COMPUTER VISION\n",
    "    [\n",
    "        (\"object detection\", 125),\n",
    "    ],\n",
    "    ###### CL\n",
    "    [(\"contrastive learning\", 344)],\n",
    "    ###### CNNs\n",
    "    [\n",
    "        (\"convolutional neural network\", 76),\n",
    "        (\"convolutional neural networks\", 130),\n",
    "        (\"cnn\", 88),\n",
    "    ],\n",
    "    ###### DIFFUSION MODELS\n",
    "    [(\"diffusion\", 69), (\"diffusion model\", 167), (\"diffusion models\", 280)],\n",
    "    ###### EXPLAINABLE AI\n",
    "    [(\"explainability\", 131), (\"explainable ai\", 92)],\n",
    "    [(\"interpretability\", 356)],\n",
    "    [(\"fairness\", 182)],\n",
    "    [(\"federated learning\", 485)],\n",
    "    ###### GANS\n",
    "    [\n",
    "        (\"generative adversarial network\", 70),\n",
    "        (\"generative adversarial networks\", 190),\n",
    "        (\"gan\", 168),\n",
    "        (\"gans\", 91),\n",
    "    ],\n",
    "    ###### GRAPH\n",
    "    [\n",
    "        (\"graph\", 48),\n",
    "        (\"graph neural network\", 230),\n",
    "        (\"graph neural networks\", 563),\n",
    "        (\"graph representation learning\", 85),\n",
    "        (\"gnn\", 64),\n",
    "    ],\n",
    "    ###### LLMS\n",
    "    [\n",
    "        (\"llm\", 80),\n",
    "        (\"large language model\", 210),\n",
    "        (\"large language models\", 447),\n",
    "        (\"prompting\", 48),\n",
    "    ],\n",
    "    [(\"knowledge distillation\", 211)],\n",
    "    [\n",
    "        (\n",
    "            \"natural language processing\",\n",
    "            433,\n",
    "        ),\n",
    "        (\"nlp\", 166),\n",
    "        (\"language model\", 105),\n",
    "        (\"language models\", 151),\n",
    "        (\"language modeling\", 85),\n",
    "        (\"machine translation\", 91),\n",
    "        (\"question answering\", 59),\n",
    "        (\"reasoning\", 85),\n",
    "    ],\n",
    "    ###### META-LEARNING\n",
    "    [(\"meta learning\", 121), (\"meta-learning\", 301)],\n",
    "    [(\"network pruning\", 48), (\"pruning\", 140)],\n",
    "    [(\"neural architecture search\", 180)],\n",
    "    [(\"optimal transport\", 165)],\n",
    "    ###### OPTIMIZATION\n",
    "    [\n",
    "        (\"stochastic gradient descent\", 77),\n",
    "        (\"stochastic optimization\", 56),\n",
    "        (\"sgd\", 86),\n",
    "        (\"optimization\", 410),\n",
    "        (\"non-convex optimization\", 66),\n",
    "        (\"convex optimization\", 57),\n",
    "        (\"gradient descent\", 86),\n",
    "        (\"combinatorial optimization\", 69),\n",
    "        (\"bayesian optimization\", 64),\n",
    "    ],\n",
    "    ###### OUT-OF-DISTRIBUTION\n",
    "    [\n",
    "        (\"out-of-distribution\", 53),\n",
    "        (\"out-of-distribution detection\", 92),\n",
    "        (\"out-of-distribution generalization\", 59),\n",
    "        (\"distribution shift\", 96),\n",
    "    ],\n",
    "    ###### PRIVACY\n",
    "    [(\"differential privacy\", 154), (\"privacy\", 99)],\n",
    "    ###### RNNs\n",
    "    [\n",
    "        (\"rnn\", 65),\n",
    "        (\"recurrent neural network\", 48),\n",
    "        (\"recurrent neural networks\", 114),\n",
    "        (\"lstm\", 66),\n",
    "    ],\n",
    "    ###### RL\n",
    "    [(\"reinforcement learning\", 1608), (\"deep reinforcement learning\", 298)],\n",
    "    [(\"active learning\", 131)],\n",
    "    [(\"model-based reinforcement learning\", 111)],\n",
    "    [(\"multi-agent reinforcement learning\", 162)],\n",
    "    [(\"multi-task learning\", 141)],\n",
    "    [(\"imitation learning\", 171)],\n",
    "    [(\"offline reinforcement learning\", 150), (\"offline rl\", 55)],\n",
    "    [(\"continual learning\", 339), (\"lifelong learning\", 82)],\n",
    "    ### NOT RL\n",
    "    [\n",
    "        (\"in-context learning\", 105),\n",
    "    ],\n",
    "    [(\"few-shot learning\", 218)],\n",
    "    [(\"robustness\", 411)],\n",
    "    [(\"self-supervised learning\", 473)],\n",
    "    [(\"semi-supervised learning\", 253)],\n",
    "    [(\"time series\", 129), (\"time series forecasting\", 54)],\n",
    "    ###### TRANSFER LEARNING\n",
    "    [\n",
    "        (\"transfer learning\", 388),\n",
    "        (\"domain adaptation\", 176),\n",
    "        (\"domain generalization\", 124),\n",
    "    ],\n",
    "    ###### VISION\n",
    "    [(\"vision transformer\", 98), (\"vision transformers\", 51)],\n",
    "    [(\"vision-language models\", 48), (\"clip\", 70)],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_keywords_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keyword_to_label = {\n",
    "    ###### ADVERSARIAL\n",
    "    \"adversarial\": \"adversarial\",\n",
    "    \"adversarial attack\": \"adversarial\",\n",
    "    \"adversarial attacks\": \"adversarial\",\n",
    "    \"adversarial defense\": \"adversarial\",\n",
    "    \"adversarial examples\": \"adversarial\",\n",
    "    \"adversarial learning\": \"adversarial\",\n",
    "    \"adversarial machine learning\": \"adversarial\",\n",
    "    \"adversarial robustness\": \"adversarial\",\n",
    "    \"adversarial training\": \"adversarial\",\n",
    "    ###### TRANSFORMERS\n",
    "    \"attention\": \"transformers\",\n",
    "    \"attention mechanism\": \"transformers\",\n",
    "    \"transformer\": \"transformers\",\n",
    "    \"transformers\": \"transformers\",\n",
    "    \"self-attention\": \"transformers\",\n",
    "    ###### AUTOENCODERS\n",
    "    \"autoencoder\": \"autoencoders\",\n",
    "    \"autoencoders\": \"autoencoders\",\n",
    "    \"vae\": \"autoencoders\",\n",
    "    \"variational autoencoder\": \"autoencoders\",\n",
    "    \"variational autoencoders\": \"autoencoders\",\n",
    "    ######\n",
    "    \"anomaly detection\": \"anomaly detection\",\n",
    "    ###### CAUSALITY\n",
    "    \"causal discovery\": \"causality\",\n",
    "    \"causal inference\": \"causality\",\n",
    "    \"causality\": \"causality\",\n",
    "    ######\n",
    "    \"clustering\": \"clustering\",\n",
    "    ###### COMPRESSION\n",
    "    \"compression\": \"compression\",\n",
    "    \"model compression\": \"compression\",\n",
    "    ######\n",
    "    \"object detection\": \"object detection\",\n",
    "    ######\n",
    "    \"contrastive learning\": \"contrastive learning\",\n",
    "    ###### CNNs\n",
    "    \"convolutional neural network\": \"CNNs\",\n",
    "    \"convolutional neural networks\": \"CNNs\",\n",
    "    \"cnn\": \"CNNs\",\n",
    "    ###### DIFFUSION MODELS\n",
    "    \"diffusion\": \"diffusion models\",\n",
    "    \"diffusion model\": \"diffusion models\",\n",
    "    \"diffusion models\": \"diffusion models\",\n",
    "    ###### EXPLAINABILITY\n",
    "    \"explainability\": \"explainability\",\n",
    "    \"explainable ai\": \"explainability\",\n",
    "    ######\n",
    "    \"interpretability\": \"interpretability\",\n",
    "    ######\n",
    "    \"fairness\": \"fairness\",\n",
    "    ######\n",
    "    \"federated learning\": \"federated learning\",\n",
    "    ###### GANs\n",
    "    \"generative adversarial network\": \"GANs\",\n",
    "    \"generative adversarial networks\": \"GANs\",\n",
    "    \"gan\": \"GANs\",\n",
    "    \"gans\": \"GANs\",\n",
    "    ###### GRAPHS\n",
    "    \"graph\": \"graphs\",\n",
    "    \"graph neural network\": \"graphs\",\n",
    "    \"graph neural networks\": \"graphs\",\n",
    "    \"graph representation learning\": \"graphs\",\n",
    "    \"gnn\": \"graphs\",\n",
    "    ###### LLMs\n",
    "    \"llm\": \"LLMs\",\n",
    "    \"large language model\": \"LLMs\",\n",
    "    \"large language models\": \"LLMs\",\n",
    "    \"prompting\": \"LLMs\",\n",
    "    ######\n",
    "    \"knowledge distillation\": \"knowledge distillation\",\n",
    "    ###### LANGUAGE MODELS\n",
    "    \"natural language processing\": \"language models\",\n",
    "    \"nlp\": \"language models\",\n",
    "    \"language model\": \"language models\",\n",
    "    \"language models\": \"language models\",\n",
    "    \"language modeling\": \"language models\",\n",
    "    \"machine translation\": \"language models\",\n",
    "    \"question answering\": \"language models\",\n",
    "    \"reasoning\": \"language models\",\n",
    "    ###### META LEARNING\n",
    "    \"meta learning\": \"meta learning\",\n",
    "    \"meta-learning\": \"meta learning\",\n",
    "    ###### PRUNING\n",
    "    \"network pruning\": \"pruning\",\n",
    "    \"pruning\": \"pruning\",\n",
    "    ######\n",
    "    \"neural architecture search\": \"neural architecture search\",\n",
    "    ######\n",
    "    \"optimal transport\": \"optimal transport\",\n",
    "    ###### OPTIMIZATION\n",
    "    \"stochastic gradient descent\": \"optimization\",\n",
    "    \"stochastic optimization\": \"optimization\",\n",
    "    \"sgd\": \"optimization\",\n",
    "    \"optimization\": \"optimization\",\n",
    "    \"non-convex optimization\": \"optimization\",\n",
    "    \"convex optimization\": \"optimization\",\n",
    "    \"gradient descent\": \"optimization\",\n",
    "    \"combinatorial optimization\": \"optimization\",\n",
    "    \"bayesian optimization\": \"optimization\",\n",
    "    ###### OUT-OF-DISTRIBUTION\n",
    "    \"out-of-distribution\": \"out-of-distribution\",\n",
    "    \"out-of-distribution detection\": \"out-of-distribution\",\n",
    "    \"out-of-distribution generalization\": \"out-of-distribution\",\n",
    "    \"distribution shift\": \"out-of-distribution\",\n",
    "    ###### PRIVACY\n",
    "    \"differential privacy\": \"privacy\",\n",
    "    \"privacy\": \"privacy\",\n",
    "    ###### RNNs\n",
    "    \"rnn\": \"RNNs\",\n",
    "    \"recurrent neural network\": \"RNNs\",\n",
    "    \"recurrent neural networks\": \"RNNs\",\n",
    "    \"lstm\": \"RNNs\",\n",
    "    ###### REINFORCEMENT LEARNING\n",
    "    \"reinforcement learning\": \"RL\",\n",
    "    \"deep reinforcement learning\": \"RL\",\n",
    "    ######\n",
    "    \"active learning\": \"active learning\",\n",
    "    ######\n",
    "    \"model-based reinforcement learning\": \"model-based RL\",\n",
    "    ######\n",
    "    \"multi-agent reinforcement learning\": \"multi-agent RL\",\n",
    "    ######\n",
    "    \"multi-task learning\": \"multi-task learning\",\n",
    "    ######\n",
    "    \"imitation learning\": \"imitation learning\",\n",
    "    ###### OFFLINE RL\n",
    "    \"offline reinforcement learning\": \"offline RL\",\n",
    "    \"offline rl\": \"offline RL\",\n",
    "    ###### CONTINUAL LEARNING\n",
    "    \"continual learning\": \"continual learning\",\n",
    "    \"lifelong learning\": \"continual learning\",\n",
    "    ######\n",
    "    \"in-context learning\": \"in-context learning\",\n",
    "    ######\n",
    "    \"few-shot learning\": \"few-shot learning\",\n",
    "    ######\n",
    "    \"robustness\": \"robustness\",\n",
    "    ######\n",
    "    \"self-supervised learning\": \"self-supervised learning\",\n",
    "    ######\n",
    "    \"semi-supervised learning\": \"semi-supervised learning\",\n",
    "    ###### TIME SERIES\n",
    "    \"time series\": \"time series\",\n",
    "    \"time series forecasting\": \"time series\",\n",
    "    ###### TRANSFER LEARNING\n",
    "    \"transfer learning\": \"transfer learning\",\n",
    "    \"domain adaptation\": \"transfer learning\",\n",
    "    \"domain generalization\": \"transfer learning\",\n",
    "    ###### ViTs\n",
    "    \"vision transformer\": \"ViTs\",\n",
    "    \"vision transformers\": \"ViTs\",\n",
    "    ###### VISION-LANGUAGE MODELS\n",
    "    \"vision-language models\": \"vision-language models\",\n",
    "    \"clip\": \"vision-language models\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(list(dict_keyword_to_label.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 13500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "palette = glasbey.create_palette(\n",
    "    palette_size=len(np.unique(list(dict_keyword_to_label.values()))),\n",
    "    lightness_bounds=(20, 75),\n",
    "    chroma_bounds=(50, 90),\n",
    ")\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CNNs': '#d21820',\n",
       " 'GANs': '#1869ff',\n",
       " 'LLMs': '#008a00',\n",
       " 'RL': '#f36dff',\n",
       " 'RNNs': '#710079',\n",
       " 'ViTs': '#eba600',\n",
       " 'active learning': '#00c2ca',\n",
       " 'adversarial': '#35ef69',\n",
       " 'anomaly detection': '#ff8692',\n",
       " 'autoencoders': '#9ea6ff',\n",
       " 'causality': '#9e28ff',\n",
       " 'clustering': '#712400',\n",
       " 'compression': '#ce0092',\n",
       " 'continual learning': '#a26500',\n",
       " 'contrastive learning': '#4528a6',\n",
       " 'diffusion models': '#005104',\n",
       " 'explainability': '#8eae45',\n",
       " 'fairness': '#ff6500',\n",
       " 'federated learning': '#8e0041',\n",
       " 'few-shot learning': '#04ae79',\n",
       " 'graphs': '#08a2eb',\n",
       " 'imitation learning': '#1cebbe',\n",
       " 'in-context learning': '#ae5db6',\n",
       " 'interpretability': '#ff2d71',\n",
       " 'knowledge distillation': '#ced200',\n",
       " 'language models': '#797d08',\n",
       " 'meta learning': '#005596',\n",
       " 'model-based RL': '#7d75d2',\n",
       " 'multi-agent RL': '#b64d61',\n",
       " 'multi-task learning': '#00be00',\n",
       " 'neural architecture search': '#e365ae',\n",
       " 'object detection': '#71caff',\n",
       " 'offline RL': '#ba75ff',\n",
       " 'optimal transport': '#71419e',\n",
       " 'optimization': '#0000fb',\n",
       " 'out-of-distribution': '#a24520',\n",
       " 'privacy': '#6931ff',\n",
       " 'pruning': '#ff9a5d',\n",
       " 'robustness': '#a600aa',\n",
       " 'self-supervised learning': '#007db2',\n",
       " 'semi-supervised learning': '#d26951',\n",
       " 'time series': '#b28e1c',\n",
       " 'transfer learning': '#9a000c',\n",
       " 'transformers': '#e30cdf',\n",
       " 'vision-language models': '#ff96df',\n",
       " 'unlabeled': 'lightgrey'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_label_to_color = dict(zip(unique_labels, palette))\n",
    "dict_label_to_color[\"unlabeled\"] = \"lightgrey\"\n",
    "dict_label_to_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def assign_labels_and_colors(\n",
    "    data, keywords_and_freqs, dict_keyword_to_label, dict_color_legend=None\n",
    "):\n",
    "    \"\"\"Assign labels and colors from list with lists of keywords.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: list of lists, len (n_samples)\n",
    "        List with lists of keywords for every paper.\n",
    "    keywords_and_freqs: list of lists, len (n_labels)\n",
    "        List of keywords groups. Contains all keywords and frequencies, with sublists of subgroups of keywords.\n",
    "    dict_keyword_to_label: dict\n",
    "        Dictionary assigning to each keyword its label (e.g. to all keywords in same subgroup same label).\n",
    "    dict_color_legend: dict, len (n_labels)\n",
    "        Dictionary assigning to each label a color.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels: array, shape (n_samples,)\n",
    "        Label for each paper.\n",
    "    colors: array, shape (n_samples,)\n",
    "        Color for each paper.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare dict_freqs\n",
    "    dict_freqs = dict(list(itertools.chain.from_iterable(keywords_and_freqs)))\n",
    "    dict_freqs[\n",
    "        \"unlabeled\"\n",
    "    ] = 1e9  # assign very large value to unlabeled for argmax\n",
    "\n",
    "    # clean empty lists of keywords from the data\n",
    "    data_without_empty = [\n",
    "        [\"unlabeled\"] if elem == [] else elem for elem in data\n",
    "    ]\n",
    "\n",
    "    # choose keywords for each paper\n",
    "    chosen_keywords = []\n",
    "    for list_keywords in data_without_empty:\n",
    "        list_keywords_filtered = [\n",
    "            elem if elem in set(dict_freqs.keys()) else \"unlabeled\"\n",
    "            for elem in list_keywords\n",
    "        ]\n",
    "\n",
    "        freqs = np.vectorize(dict_freqs.get)(list_keywords_filtered)\n",
    "\n",
    "        chosen_keyword = list_keywords_filtered[np.argmin(freqs)]\n",
    "        chosen_keywords.append(chosen_keyword)\n",
    "\n",
    "    chosen_keywords = np.array(chosen_keywords)\n",
    "\n",
    "    # map chosen keywords to labels\n",
    "    dict_keyword_to_label[\"unlabeled\"] = \"unlabeled\"\n",
    "    labels = np.vectorize(dict_keyword_to_label.get)(chosen_keywords)\n",
    "\n",
    "    # colors\n",
    "    colors = np.vectorize(dict_color_legend.get)(labels)\n",
    "\n",
    "    return labels, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 604 ms, sys: 0 ns, total: 604 ms\n",
      "Wall time: 596 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels_iclr, colors_iclr = assign_labels_and_colors(\n",
    "    iclr2024.keywords.to_list(),\n",
    "    final_keywords_groups,\n",
    "    dict_keyword_to_label,\n",
    "    dict_label_to_color,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "np.save(variables_path / \"labels_iclr\", labels_iclr)\n",
    "np.save(variables_path / \"colors_iclr\", colors_iclr)\n",
    "\n",
    "f = open(variables_path / \"dict_label_to_color.pkl\", \"wb\")\n",
    "pickle.dump(dict_label_to_color, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of unlabeled papers:  46.60257721415422\n",
      "Number of unlabeled papers:  11392\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of unlabeled papers: \",\n",
    "    np.sum(labels_iclr == \"unlabeled\") / len(labels_iclr) * 100,\n",
    ")\n",
    "print(\n",
    "    \"Number of unlabeled papers: \",\n",
    "    np.sum(labels_iclr == \"unlabeled\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers without any keywords:  8.71752914706484\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Papers without any keywords: \",\n",
    "    np.sum([1 if elem == [] else 0 for elem in iclr2024.keywords])\n",
    "    / len(labels_iclr)\n",
    "    * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['unsupervised learning']), list([]),\n",
       "       list(['unsupervised learning', 'deep learning']), list([]),\n",
       "       list(['deep learning', 'supervised learning']),\n",
       "       list(['deep learning', 'unsupervised learning']), list([]),\n",
       "       list(['theory', 'deep learning']), list([]),\n",
       "       list(['deep learning', 'multi-modal learning', 'structured prediction']),\n",
       "       list(['deep learning']), list([]),\n",
       "       list(['deep learning', 'theory']),\n",
       "       list(['deep learning', 'unsupervised learning', 'applications']),\n",
       "       list(['deep learning']), list(['theory', 'deep learning']),\n",
       "       list([]), list(['deep learning', 'applications']), list([]),\n",
       "       list([]), list(['deep learning', 'unsupervised learning']),\n",
       "       list(['deep learning']), list([]),\n",
       "       list(['deep learning', 'supervised learning']),\n",
       "       list(['deep learning', 'unsupervised learning']),\n",
       "       list(['computer vision', 'deep learning']),\n",
       "       list(['deep learning', 'computer vision']),\n",
       "       list(['unsupervised learning']),\n",
       "       list(['deep learning', 'computer vision']),\n",
       "       list(['deep learning']), list(['theory', 'deep learning']),\n",
       "       list(['deep learning', 'unsupervised learning']),\n",
       "       list(['deep learning', 'computer vision']),\n",
       "       list(['deep learning', 'supervised learning', 'unsupervised learning']),\n",
       "       list(['computer vision', 'supervised learning']), list([]),\n",
       "       list([]), list([]), list([]), list([]),\n",
       "       list(['theory', 'deep learning']), list([]), list([]),\n",
       "       list(['unsupervised learning']),\n",
       "       list(['games', 'supervised learning', 'deep learning']),\n",
       "       list(['unsupervised learning', 'computer vision', 'deep learning', 'applications']),\n",
       "       list(['supervised learning', 'deep learning']),\n",
       "       list(['unsupervised learning', 'deep learning']),\n",
       "       list(['deep learning', 'speech', 'structured prediction']),\n",
       "       list(['theory', 'deep learning'])], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of papers with keywords that have not being assigned a label\n",
    "# We can see that they contain very general or very specific keywords that were filtered out in our selection\n",
    "iclr2024.keywords.to_numpy()[labels_iclr == \"unlabeled\"][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column to dataframe and resave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-Hhnslg</td>\n",
       "      <td>Prototypical Networks for Few-shot Learning</td>\n",
       "      <td>A recent approach to few-shot classification c...</td>\n",
       "      <td>Jake Snell, Kevin Swersky, Richard Zemel</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>[deep learning, transfer learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-q5Pqxl</td>\n",
       "      <td>Machine Comprehension Using Match-LSTM and Ans...</td>\n",
       "      <td>Machine comprehension of text is an important ...</td>\n",
       "      <td>Shuohang Wang, Jing Jiang</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 7]</td>\n",
       "      <td>[natural language processing, deep learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16Jem9xe</td>\n",
       "      <td>Learning in Implicit Generative Models</td>\n",
       "      <td>Generative adversarial networks (GANs) provide...</td>\n",
       "      <td>Shakir Mohamed, Balaji Lakshminarayanan</td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[8, 7, 6]</td>\n",
       "      <td>[unsupervised learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16dGcqlx</td>\n",
       "      <td>Third Person Imitation Learning</td>\n",
       "      <td>Reinforcement learning (RL) makes it possible ...</td>\n",
       "      <td>Bradly C Stadie, Pieter Abbeel, Ilya Sutskever</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>B184E5qee</td>\n",
       "      <td>Improving Neural Language Models with a Contin...</td>\n",
       "      <td>We propose an extension to neural network lang...</td>\n",
       "      <td>Edouard Grave, Armand Joulin, Nicolas Usunier</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[7, 9, 5]</td>\n",
       "      <td>[natural language processing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year         id                                              title  \\\n",
       "0  2017  B1-Hhnslg        Prototypical Networks for Few-shot Learning   \n",
       "1  2017  B1-q5Pqxl  Machine Comprehension Using Match-LSTM and Ans...   \n",
       "2  2017  B16Jem9xe             Learning in Implicit Generative Models   \n",
       "3  2017  B16dGcqlx                    Third Person Imitation Learning   \n",
       "4  2017  B184E5qee  Improving Neural Language Models with a Contin...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A recent approach to few-shot classification c...   \n",
       "1  Machine comprehension of text is an important ...   \n",
       "2  Generative adversarial networks (GANs) provide...   \n",
       "3  Reinforcement learning (RL) makes it possible ...   \n",
       "4  We propose an extension to neural network lang...   \n",
       "\n",
       "                                          authors                  decision  \\\n",
       "0        Jake Snell, Kevin Swersky, Richard Zemel                    Reject   \n",
       "1                       Shuohang Wang, Jing Jiang           Accept (Poster)   \n",
       "2         Shakir Mohamed, Balaji Lakshminarayanan  Invite to Workshop Track   \n",
       "3  Bradly C Stadie, Pieter Abbeel, Ilya Sutskever           Accept (Poster)   \n",
       "4   Edouard Grave, Armand Joulin, Nicolas Usunier           Accept (Poster)   \n",
       "\n",
       "      scores                                      keywords  \n",
       "0  [6, 4, 5]            [deep learning, transfer learning]  \n",
       "1  [6, 6, 7]  [natural language processing, deep learning]  \n",
       "2  [8, 7, 6]                       [unsupervised learning]  \n",
       "3  [6, 5, 6]                                            []  \n",
       "4  [7, 9, 5]                 [natural language processing]  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr2024.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iclr2024[\"labels\"] = labels_iclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-Hhnslg</td>\n",
       "      <td>Prototypical Networks for Few-shot Learning</td>\n",
       "      <td>A recent approach to few-shot classification c...</td>\n",
       "      <td>Jake Snell, Kevin Swersky, Richard Zemel</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>[deep learning, transfer learning]</td>\n",
       "      <td>transfer learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-q5Pqxl</td>\n",
       "      <td>Machine Comprehension Using Match-LSTM and Ans...</td>\n",
       "      <td>Machine comprehension of text is an important ...</td>\n",
       "      <td>Shuohang Wang, Jing Jiang</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 7]</td>\n",
       "      <td>[natural language processing, deep learning]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16Jem9xe</td>\n",
       "      <td>Learning in Implicit Generative Models</td>\n",
       "      <td>Generative adversarial networks (GANs) provide...</td>\n",
       "      <td>Shakir Mohamed, Balaji Lakshminarayanan</td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[8, 7, 6]</td>\n",
       "      <td>[unsupervised learning]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16dGcqlx</td>\n",
       "      <td>Third Person Imitation Learning</td>\n",
       "      <td>Reinforcement learning (RL) makes it possible ...</td>\n",
       "      <td>Bradly C Stadie, Pieter Abbeel, Ilya Sutskever</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>B184E5qee</td>\n",
       "      <td>Improving Neural Language Models with a Contin...</td>\n",
       "      <td>We propose an extension to neural network lang...</td>\n",
       "      <td>Edouard Grave, Armand Joulin, Nicolas Usunier</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[7, 9, 5]</td>\n",
       "      <td>[natural language processing]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year         id                                              title  \\\n",
       "0  2017  B1-Hhnslg        Prototypical Networks for Few-shot Learning   \n",
       "1  2017  B1-q5Pqxl  Machine Comprehension Using Match-LSTM and Ans...   \n",
       "2  2017  B16Jem9xe             Learning in Implicit Generative Models   \n",
       "3  2017  B16dGcqlx                    Third Person Imitation Learning   \n",
       "4  2017  B184E5qee  Improving Neural Language Models with a Contin...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A recent approach to few-shot classification c...   \n",
       "1  Machine comprehension of text is an important ...   \n",
       "2  Generative adversarial networks (GANs) provide...   \n",
       "3  Reinforcement learning (RL) makes it possible ...   \n",
       "4  We propose an extension to neural network lang...   \n",
       "\n",
       "                                          authors                  decision  \\\n",
       "0        Jake Snell, Kevin Swersky, Richard Zemel                    Reject   \n",
       "1                       Shuohang Wang, Jing Jiang           Accept (Poster)   \n",
       "2         Shakir Mohamed, Balaji Lakshminarayanan  Invite to Workshop Track   \n",
       "3  Bradly C Stadie, Pieter Abbeel, Ilya Sutskever           Accept (Poster)   \n",
       "4   Edouard Grave, Armand Joulin, Nicolas Usunier           Accept (Poster)   \n",
       "\n",
       "      scores                                      keywords             labels  \n",
       "0  [6, 4, 5]            [deep learning, transfer learning]  transfer learning  \n",
       "1  [6, 6, 7]  [natural language processing, deep learning]    language models  \n",
       "2  [8, 7, 6]                       [unsupervised learning]          unlabeled  \n",
       "3  [6, 5, 6]                                            []          unlabeled  \n",
       "4  [7, 9, 5]                 [natural language processing]    language models  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr2024.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "iclr2024.to_parquet(\n",
    "    data_path / \"iclr24v2.parquet\",\n",
    "    index=False,\n",
    "    engine=\"pyarrow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print latex table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>transfer learning</td>\n",
       "      <td>domain generalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ViTs</td>\n",
       "      <td>vision transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ViTs</td>\n",
       "      <td>vision transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>vision-language models</td>\n",
       "      <td>vision-language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>vision-language models</td>\n",
       "      <td>clip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows 칑 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 class_name                 keyword\n",
       "0               adversarial             adversarial\n",
       "1               adversarial      adversarial attack\n",
       "2               adversarial     adversarial attacks\n",
       "3               adversarial     adversarial defense\n",
       "4               adversarial    adversarial examples\n",
       "..                      ...                     ...\n",
       "106       transfer learning   domain generalization\n",
       "107                    ViTs      vision transformer\n",
       "108                    ViTs     vision transformers\n",
       "109  vision-language models  vision-language models\n",
       "110  vision-language models                    clip\n",
       "\n",
       "[111 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table = pd.DataFrame(\n",
    "    {\n",
    "        \"class_name\": list(dict_keyword_to_label.values()),\n",
    "        \"keyword\": list(dict_keyword_to_label.keys()),\n",
    "    },\n",
    ")\n",
    "df_table.drop(index=111, inplace=True)  # delete \"unlabeled\" row\n",
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add frequency per keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adversarial': 60,\n",
       " 'adversarial attack': 121,\n",
       " 'adversarial attacks': 106,\n",
       " 'adversarial defense': 50,\n",
       " 'adversarial examples': 196,\n",
       " 'adversarial learning': 93,\n",
       " 'adversarial machine learning': 54,\n",
       " 'adversarial robustness': 241,\n",
       " 'adversarial training': 217,\n",
       " 'attention': 183,\n",
       " 'attention mechanism': 53,\n",
       " 'transformer': 340,\n",
       " 'transformers': 261,\n",
       " 'self-attention': 73,\n",
       " 'autoencoder': 63,\n",
       " 'autoencoders': 52,\n",
       " 'vae': 71,\n",
       " 'variational autoencoder': 93,\n",
       " 'variational autoencoders': 83,\n",
       " 'anomaly detection': 109,\n",
       " 'causal discovery': 53,\n",
       " 'causal inference': 104,\n",
       " 'causality': 80,\n",
       " 'clustering': 116,\n",
       " 'compression': 121,\n",
       " 'model compression': 135,\n",
       " 'object detection': 125,\n",
       " 'contrastive learning': 344,\n",
       " 'convolutional neural network': 76,\n",
       " 'convolutional neural networks': 130,\n",
       " 'cnn': 88,\n",
       " 'diffusion': 69,\n",
       " 'diffusion model': 167,\n",
       " 'diffusion models': 280,\n",
       " 'explainability': 131,\n",
       " 'explainable ai': 92,\n",
       " 'interpretability': 356,\n",
       " 'fairness': 182,\n",
       " 'federated learning': 485,\n",
       " 'generative adversarial network': 70,\n",
       " 'generative adversarial networks': 190,\n",
       " 'gan': 168,\n",
       " 'gans': 91,\n",
       " 'graph': 48,\n",
       " 'graph neural network': 230,\n",
       " 'graph neural networks': 563,\n",
       " 'graph representation learning': 85,\n",
       " 'gnn': 64,\n",
       " 'llm': 80,\n",
       " 'large language model': 210,\n",
       " 'large language models': 447,\n",
       " 'prompting': 48,\n",
       " 'knowledge distillation': 211,\n",
       " 'natural language processing': 433,\n",
       " 'nlp': 166,\n",
       " 'language model': 105,\n",
       " 'language models': 151,\n",
       " 'language modeling': 85,\n",
       " 'machine translation': 91,\n",
       " 'question answering': 59,\n",
       " 'reasoning': 85,\n",
       " 'meta learning': 121,\n",
       " 'meta-learning': 301,\n",
       " 'network pruning': 48,\n",
       " 'pruning': 140,\n",
       " 'neural architecture search': 180,\n",
       " 'optimal transport': 165,\n",
       " 'stochastic gradient descent': 77,\n",
       " 'stochastic optimization': 56,\n",
       " 'sgd': 86,\n",
       " 'optimization': 410,\n",
       " 'non-convex optimization': 66,\n",
       " 'convex optimization': 57,\n",
       " 'gradient descent': 86,\n",
       " 'combinatorial optimization': 69,\n",
       " 'bayesian optimization': 64,\n",
       " 'out-of-distribution': 53,\n",
       " 'out-of-distribution detection': 92,\n",
       " 'out-of-distribution generalization': 59,\n",
       " 'distribution shift': 96,\n",
       " 'differential privacy': 154,\n",
       " 'privacy': 99,\n",
       " 'rnn': 65,\n",
       " 'recurrent neural network': 48,\n",
       " 'recurrent neural networks': 114,\n",
       " 'lstm': 66,\n",
       " 'reinforcement learning': 1608,\n",
       " 'deep reinforcement learning': 298,\n",
       " 'active learning': 131,\n",
       " 'model-based reinforcement learning': 111,\n",
       " 'multi-agent reinforcement learning': 162,\n",
       " 'multi-task learning': 141,\n",
       " 'imitation learning': 171,\n",
       " 'offline reinforcement learning': 150,\n",
       " 'offline rl': 55,\n",
       " 'continual learning': 339,\n",
       " 'lifelong learning': 82,\n",
       " 'in-context learning': 105,\n",
       " 'few-shot learning': 218,\n",
       " 'robustness': 411,\n",
       " 'self-supervised learning': 473,\n",
       " 'semi-supervised learning': 253,\n",
       " 'time series': 129,\n",
       " 'time series forecasting': 54,\n",
       " 'transfer learning': 388,\n",
       " 'domain adaptation': 176,\n",
       " 'domain generalization': 124,\n",
       " 'vision transformer': 98,\n",
       " 'vision transformers': 51,\n",
       " 'vision-language models': 48,\n",
       " 'clip': 70}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "dict_freqs = dict(list(itertools.chain.from_iterable(final_keywords_groups)))\n",
    "dict_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table[\"keyword_frequency\"] = df_table[\"keyword\"].map(dict_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>keyword</th>\n",
       "      <th>keyword_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attack</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attacks</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial defense</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial examples</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>transfer learning</td>\n",
       "      <td>domain generalization</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ViTs</td>\n",
       "      <td>vision transformer</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ViTs</td>\n",
       "      <td>vision transformers</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>vision-language models</td>\n",
       "      <td>vision-language models</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>vision-language models</td>\n",
       "      <td>clip</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows 칑 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 class_name                 keyword  keyword_frequency\n",
       "0               adversarial             adversarial                 60\n",
       "1               adversarial      adversarial attack                121\n",
       "2               adversarial     adversarial attacks                106\n",
       "3               adversarial     adversarial defense                 50\n",
       "4               adversarial    adversarial examples                196\n",
       "..                      ...                     ...                ...\n",
       "106       transfer learning   domain generalization                124\n",
       "107                    ViTs      vision transformer                 98\n",
       "108                    ViTs     vision transformers                 51\n",
       "109  vision-language models  vision-language models                 48\n",
       "110  vision-language models                    clip                 70\n",
       "\n",
       "[111 rows x 3 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add n_samples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/variables/iclr24v2a/labels_iclr.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m labels_iclr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels_iclr.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/variables/iclr24v2a/labels_iclr.npy'"
     ]
    }
   ],
   "source": [
    "labels_iclr = np.load(variables_path / \"labels_iclr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_for_samples, class_n_samples = np.unique(\n",
    "    labels_iclr, return_counts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CNNs': 247,\n",
       " 'GANs': 380,\n",
       " 'LLMs': 538,\n",
       " 'RL': 1266,\n",
       " 'RNNs': 250,\n",
       " 'ViTs': 130,\n",
       " 'active learning': 111,\n",
       " 'adversarial': 870,\n",
       " 'anomaly detection': 87,\n",
       " 'autoencoders': 330,\n",
       " 'causality': 202,\n",
       " 'clustering': 97,\n",
       " 'compression': 214,\n",
       " 'continual learning': 313,\n",
       " 'contrastive learning': 244,\n",
       " 'diffusion models': 443,\n",
       " 'explainability': 194,\n",
       " 'fairness': 133,\n",
       " 'federated learning': 298,\n",
       " 'few-shot learning': 157,\n",
       " 'graphs': 730,\n",
       " 'imitation learning': 144,\n",
       " 'in-context learning': 87,\n",
       " 'interpretability': 177,\n",
       " 'knowledge distillation': 150,\n",
       " 'language models': 802,\n",
       " 'meta learning': 275,\n",
       " 'model-based RL': 105,\n",
       " 'multi-agent RL': 151,\n",
       " 'multi-task learning': 121,\n",
       " 'neural architecture search': 138,\n",
       " 'object detection': 106,\n",
       " 'offline RL': 184,\n",
       " 'optimal transport': 132,\n",
       " 'optimization': 790,\n",
       " 'out-of-distribution': 275,\n",
       " 'privacy': 215,\n",
       " 'pruning': 133,\n",
       " 'robustness': 175,\n",
       " 'self-supervised learning': 259,\n",
       " 'semi-supervised learning': 176,\n",
       " 'time series': 140,\n",
       " 'transfer learning': 419,\n",
       " 'transformers': 557,\n",
       " 'unlabeled': 11392,\n",
       " 'vision-language models': 108}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_n_samples_per_class = dict(zip(class_name_for_samples, class_n_samples))\n",
    "dict_n_samples_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_n_samples_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table[\"n_samples\"] = df_table[\"class_name\"].map(dict_n_samples_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>keyword</th>\n",
       "      <th>keyword_frequency</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>60</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attack</td>\n",
       "      <td>121</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attacks</td>\n",
       "      <td>106</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial defense</td>\n",
       "      <td>50</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial examples</td>\n",
       "      <td>196</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>transfer learning</td>\n",
       "      <td>domain generalization</td>\n",
       "      <td>124</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ViTs</td>\n",
       "      <td>vision transformer</td>\n",
       "      <td>98</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ViTs</td>\n",
       "      <td>vision transformers</td>\n",
       "      <td>51</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>vision-language models</td>\n",
       "      <td>vision-language models</td>\n",
       "      <td>48</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>vision-language models</td>\n",
       "      <td>clip</td>\n",
       "      <td>70</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows 칑 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 class_name                 keyword  keyword_frequency  \\\n",
       "0               adversarial             adversarial                 60   \n",
       "1               adversarial      adversarial attack                121   \n",
       "2               adversarial     adversarial attacks                106   \n",
       "3               adversarial     adversarial defense                 50   \n",
       "4               adversarial    adversarial examples                196   \n",
       "..                      ...                     ...                ...   \n",
       "106       transfer learning   domain generalization                124   \n",
       "107                    ViTs      vision transformer                 98   \n",
       "108                    ViTs     vision transformers                 51   \n",
       "109  vision-language models  vision-language models                 48   \n",
       "110  vision-language models                    clip                 70   \n",
       "\n",
       "     n_samples  \n",
       "0          870  \n",
       "1          870  \n",
       "2          870  \n",
       "3          870  \n",
       "4          870  \n",
       "..         ...  \n",
       "106        419  \n",
       "107        130  \n",
       "108        130  \n",
       "109        108  \n",
       "110        108  \n",
       "\n",
       "[111 rows x 4 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Add number of keywords per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name, class_counts = np.unique(\n",
    "    list(dict_keyword_to_label.values()), return_counts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CNNs': 3,\n",
       " 'GANs': 4,\n",
       " 'LLMs': 4,\n",
       " 'RL': 2,\n",
       " 'RNNs': 4,\n",
       " 'ViTs': 2,\n",
       " 'active learning': 1,\n",
       " 'adversarial': 9,\n",
       " 'anomaly detection': 1,\n",
       " 'autoencoders': 5,\n",
       " 'causality': 3,\n",
       " 'clustering': 1,\n",
       " 'compression': 2,\n",
       " 'continual learning': 2,\n",
       " 'contrastive learning': 1,\n",
       " 'diffusion models': 3,\n",
       " 'explainability': 2,\n",
       " 'fairness': 1,\n",
       " 'federated learning': 1,\n",
       " 'few-shot learning': 1,\n",
       " 'graphs': 5,\n",
       " 'imitation learning': 1,\n",
       " 'in-context learning': 1,\n",
       " 'interpretability': 1,\n",
       " 'knowledge distillation': 1,\n",
       " 'language models': 8,\n",
       " 'meta learning': 2,\n",
       " 'model-based RL': 1,\n",
       " 'multi-agent RL': 1,\n",
       " 'multi-task learning': 1,\n",
       " 'neural architecture search': 1,\n",
       " 'object detection': 1,\n",
       " 'offline RL': 2,\n",
       " 'optimal transport': 1,\n",
       " 'optimization': 9,\n",
       " 'out-of-distribution': 4,\n",
       " 'privacy': 2,\n",
       " 'pruning': 2,\n",
       " 'robustness': 1,\n",
       " 'self-supervised learning': 1,\n",
       " 'semi-supervised learning': 1,\n",
       " 'time series': 2,\n",
       " 'transfer learning': 3,\n",
       " 'transformers': 5,\n",
       " 'unlabeled': 1,\n",
       " 'vision-language models': 2}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_keywords_per_class = dict(zip(class_name, class_counts))\n",
    "number_keywords_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table[\"keywords_per_class\"] = df_table[\"class_name\"].map(\n",
    "    number_keywords_per_class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>keyword</th>\n",
       "      <th>keyword_frequency</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>keywords_per_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>60</td>\n",
       "      <td>870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attack</td>\n",
       "      <td>121</td>\n",
       "      <td>870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attacks</td>\n",
       "      <td>106</td>\n",
       "      <td>870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial defense</td>\n",
       "      <td>50</td>\n",
       "      <td>870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial examples</td>\n",
       "      <td>196</td>\n",
       "      <td>870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>transfer learning</td>\n",
       "      <td>domain generalization</td>\n",
       "      <td>124</td>\n",
       "      <td>419</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ViTs</td>\n",
       "      <td>vision transformer</td>\n",
       "      <td>98</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ViTs</td>\n",
       "      <td>vision transformers</td>\n",
       "      <td>51</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>vision-language models</td>\n",
       "      <td>vision-language models</td>\n",
       "      <td>48</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>vision-language models</td>\n",
       "      <td>clip</td>\n",
       "      <td>70</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows 칑 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 class_name                 keyword  keyword_frequency  \\\n",
       "0               adversarial             adversarial                 60   \n",
       "1               adversarial      adversarial attack                121   \n",
       "2               adversarial     adversarial attacks                106   \n",
       "3               adversarial     adversarial defense                 50   \n",
       "4               adversarial    adversarial examples                196   \n",
       "..                      ...                     ...                ...   \n",
       "106       transfer learning   domain generalization                124   \n",
       "107                    ViTs      vision transformer                 98   \n",
       "108                    ViTs     vision transformers                 51   \n",
       "109  vision-language models  vision-language models                 48   \n",
       "110  vision-language models                    clip                 70   \n",
       "\n",
       "     n_samples  keywords_per_class  \n",
       "0          870                   9  \n",
       "1          870                   9  \n",
       "2          870                   9  \n",
       "3          870                   9  \n",
       "4          870                   9  \n",
       "..         ...                 ...  \n",
       "106        419                   3  \n",
       "107        130                   2  \n",
       "108        130                   2  \n",
       "109        108                   2  \n",
       "110        108                   2  \n",
       "\n",
       "[111 rows x 5 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort table by n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table.sort_values(\n",
    "    by=[\"n_samples\", \"class_name\"], ascending=False, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>keyword</th>\n",
       "      <th>keyword_frequency</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>keywords_per_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>RL</td>\n",
       "      <td>reinforcement learning</td>\n",
       "      <td>1608</td>\n",
       "      <td>1266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>RL</td>\n",
       "      <td>deep reinforcement learning</td>\n",
       "      <td>298</td>\n",
       "      <td>1266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>60</td>\n",
       "      <td>870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attack</td>\n",
       "      <td>121</td>\n",
       "      <td>870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attacks</td>\n",
       "      <td>106</td>\n",
       "      <td>870</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>object detection</td>\n",
       "      <td>object detection</td>\n",
       "      <td>125</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>model-based RL</td>\n",
       "      <td>model-based reinforcement learning</td>\n",
       "      <td>111</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>clustering</td>\n",
       "      <td>clustering</td>\n",
       "      <td>116</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>in-context learning</td>\n",
       "      <td>in-context learning</td>\n",
       "      <td>105</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>anomaly detection</td>\n",
       "      <td>anomaly detection</td>\n",
       "      <td>109</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows 칑 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             class_name                             keyword  \\\n",
       "86                   RL              reinforcement learning   \n",
       "87                   RL         deep reinforcement learning   \n",
       "0           adversarial                         adversarial   \n",
       "1           adversarial                  adversarial attack   \n",
       "2           adversarial                 adversarial attacks   \n",
       "..                  ...                                 ...   \n",
       "26     object detection                    object detection   \n",
       "89       model-based RL  model-based reinforcement learning   \n",
       "23           clustering                          clustering   \n",
       "97  in-context learning                 in-context learning   \n",
       "19    anomaly detection                   anomaly detection   \n",
       "\n",
       "    keyword_frequency  n_samples  keywords_per_class  \n",
       "86               1608       1266                   2  \n",
       "87                298       1266                   2  \n",
       "0                  60        870                   9  \n",
       "1                 121        870                   9  \n",
       "2                 106        870                   9  \n",
       "..                ...        ...                 ...  \n",
       "26                125        106                   1  \n",
       "89                111        105                   1  \n",
       "23                116         97                   1  \n",
       "97                105         87                   1  \n",
       "19                109         87                   1  \n",
       "\n",
       "[111 rows x 5 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\midrule\n",
      "\\multirow{2}{*}{RL} & \\multirow{2}{*}{1266} & reinforcement learning & 1608    \\\\ \n",
      "                      &   &  deep reinforcement learning & 298 \\\\ \n",
      "\\midrule\n",
      "\\multirow{9}{*}{Adversarial} & \\multirow{9}{*}{870} & adversarial & 60    \\\\ \n",
      "                      &   &  adversarial attack & 121 \\\\ \n",
      "                      &   &  adversarial attacks & 106 \\\\ \n",
      "                      &   &  adversarial defense & 50 \\\\ \n",
      "                      &   &  adversarial examples & 196 \\\\ \n",
      "                      &   &  adversarial learning & 93 \\\\ \n",
      "                      &   &  adversarial machine learning & 54 \\\\ \n",
      "                      &   &  adversarial robustness & 241 \\\\ \n",
      "                      &   &  adversarial training & 217 \\\\ \n",
      "\\midrule\n",
      "\\multirow{8}{*}{Language models} & \\multirow{8}{*}{802} & natural language processing & 433    \\\\ \n",
      "                      &   &  nlp & 166 \\\\ \n",
      "                      &   &  language model & 105 \\\\ \n",
      "                      &   &  language models & 151 \\\\ \n",
      "                      &   &  language modeling & 85 \\\\ \n",
      "                      &   &  machine translation & 91 \\\\ \n",
      "                      &   &  question answering & 59 \\\\ \n",
      "                      &   &  reasoning & 85 \\\\ \n",
      "\\midrule\n",
      "\\multirow{9}{*}{Optimization} & \\multirow{9}{*}{790} & stochastic gradient descent & 77    \\\\ \n",
      "                      &   &  stochastic optimization & 56 \\\\ \n",
      "                      &   &  sgd & 86 \\\\ \n",
      "                      &   &  optimization & 410 \\\\ \n",
      "                      &   &  non-convex optimization & 66 \\\\ \n",
      "                      &   &  convex optimization & 57 \\\\ \n",
      "                      &   &  gradient descent & 86 \\\\ \n",
      "                      &   &  combinatorial optimization & 69 \\\\ \n",
      "                      &   &  bayesian optimization & 64 \\\\ \n",
      "\\midrule\n",
      "\\multirow{5}{*}{Graphs} & \\multirow{5}{*}{730} & graph & 48    \\\\ \n",
      "                      &   &  graph neural network & 230 \\\\ \n",
      "                      &   &  graph neural networks & 563 \\\\ \n",
      "                      &   &  graph representation learning & 85 \\\\ \n",
      "                      &   &  gnn & 64 \\\\ \n",
      "\\midrule\n",
      "\\multirow{5}{*}{Transformers} & \\multirow{5}{*}{557} & attention & 183    \\\\ \n",
      "                      &   &  attention mechanism & 53 \\\\ \n",
      "                      &   &  transformer & 340 \\\\ \n",
      "                      &   &  transformers & 261 \\\\ \n",
      "                      &   &  self-attention & 73 \\\\ \n",
      "\\midrule\n",
      "\\multirow{4}{*}{LLMs} & \\multirow{4}{*}{538} & llm & 80    \\\\ \n",
      "                      &   &  large language model & 210 \\\\ \n",
      "                      &   &  large language models & 447 \\\\ \n",
      "                      &   &  prompting & 48 \\\\ \n",
      "\\midrule\n",
      "\\multirow{3}{*}{Diffusion models} & \\multirow{3}{*}{443} & diffusion & 69    \\\\ \n",
      "                      &   &  diffusion model & 167 \\\\ \n",
      "                      &   &  diffusion models & 280 \\\\ \n",
      "\\midrule\n",
      "\\multirow{3}{*}{Transfer learning} & \\multirow{3}{*}{419} & transfer learning & 388    \\\\ \n",
      "                      &   &  domain adaptation & 176 \\\\ \n",
      "                      &   &  domain generalization & 124 \\\\ \n",
      "\\midrule\n",
      "\\multirow{4}{*}{GANs} & \\multirow{4}{*}{380} & generative adversarial network & 70    \\\\ \n",
      "                      &   &  generative adversarial networks & 190 \\\\ \n",
      "                      &   &  gan & 168 \\\\ \n",
      "                      &   &  gans & 91 \\\\ \n",
      "\\midrule\n",
      "\\multirow{5}{*}{Autoencoders} & \\multirow{5}{*}{330} & autoencoder & 63    \\\\ \n",
      "                      &   &  autoencoders & 52 \\\\ \n",
      "                      &   &  vae & 71 \\\\ \n",
      "                      &   &  variational autoencoder & 93 \\\\ \n",
      "                      &   &  variational autoencoders & 83 \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{Continual learning} & \\multirow{2}{*}{313} & continual learning & 339    \\\\ \n",
      "                      &   &  lifelong learning & 82 \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Federated learning} & \\multirow{1}{*}{298} & federated learning & 485    \\\\ \n",
      "\\midrule\n",
      "\\multirow{4}{*}{Out-of-distribution} & \\multirow{4}{*}{275} & out-of-distribution & 53    \\\\ \n",
      "                      &   &  out-of-distribution detection & 92 \\\\ \n",
      "                      &   &  out-of-distribution generalization & 59 \\\\ \n",
      "                      &   &  distribution shift & 96 \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{Meta learning} & \\multirow{2}{*}{275} & meta learning & 121    \\\\ \n",
      "                      &   &  meta-learning & 301 \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Self-supervised learning} & \\multirow{1}{*}{259} & self-supervised learning & 473    \\\\ \n",
      "\\midrule\n",
      "\\multirow{4}{*}{RNNs} & \\multirow{4}{*}{250} & rnn & 65    \\\\ \n",
      "                      &   &  recurrent neural network & 48 \\\\ \n",
      "                      &   &  recurrent neural networks & 114 \\\\ \n",
      "                      &   &  lstm & 66 \\\\ \n",
      "\\midrule\n",
      "\\multirow{3}{*}{CNNs} & \\multirow{3}{*}{247} & convolutional neural network & 76    \\\\ \n",
      "                      &   &  convolutional neural networks & 130 \\\\ \n",
      "                      &   &  cnn & 88 \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Contrastive learning} & \\multirow{1}{*}{244} & contrastive learning & 344    \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{Privacy} & \\multirow{2}{*}{215} & differential privacy & 154    \\\\ \n",
      "                      &   &  privacy & 99 \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{Compression} & \\multirow{2}{*}{214} & compression & 121    \\\\ \n",
      "                      &   &  model compression & 135 \\\\ \n",
      "\\midrule\n",
      "\\multirow{3}{*}{Causality} & \\multirow{3}{*}{202} & causal discovery & 53    \\\\ \n",
      "                      &   &  causal inference & 104 \\\\ \n",
      "                      &   &  causality & 80 \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{Explainability} & \\multirow{2}{*}{194} & explainability & 131    \\\\ \n",
      "                      &   &  explainable ai & 92 \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{Offline RL} & \\multirow{2}{*}{184} & offline reinforcement learning & 150    \\\\ \n",
      "                      &   &  offline rl & 55 \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Interpretability} & \\multirow{1}{*}{177} & interpretability & 356    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Semi-supervised learning} & \\multirow{1}{*}{176} & semi-supervised learning & 253    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Robustness} & \\multirow{1}{*}{175} & robustness & 411    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Few-shot learning} & \\multirow{1}{*}{157} & few-shot learning & 218    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Multi-agent RL} & \\multirow{1}{*}{151} & multi-agent reinforcement learning & 162    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Knowledge distillation} & \\multirow{1}{*}{150} & knowledge distillation & 211    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Imitation learning} & \\multirow{1}{*}{144} & imitation learning & 171    \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{Time series} & \\multirow{2}{*}{140} & time series & 129    \\\\ \n",
      "                      &   &  time series forecasting & 54 \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Neural architecture search} & \\multirow{1}{*}{138} & neural architecture search & 180    \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{Pruning} & \\multirow{2}{*}{133} & network pruning & 48    \\\\ \n",
      "                      &   &  pruning & 140 \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Fairness} & \\multirow{1}{*}{133} & fairness & 182    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Optimal transport} & \\multirow{1}{*}{132} & optimal transport & 165    \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{ViTs} & \\multirow{2}{*}{130} & vision transformer & 98    \\\\ \n",
      "                      &   &  vision transformers & 51 \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Multi-task learning} & \\multirow{1}{*}{121} & multi-task learning & 141    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Active learning} & \\multirow{1}{*}{111} & active learning & 131    \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{Vision-language models} & \\multirow{2}{*}{108} & vision-language models & 48    \\\\ \n",
      "                      &   &  clip & 70 \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Object detection} & \\multirow{1}{*}{106} & object detection & 125    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Model-based RL} & \\multirow{1}{*}{105} & model-based reinforcement learning & 111    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Clustering} & \\multirow{1}{*}{97} & clustering & 116    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{In-context learning} & \\multirow{1}{*}{87} & in-context learning & 105    \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{Anomaly detection} & \\multirow{1}{*}{87} & anomaly detection & 109    \\\\ \n"
     ]
    }
   ],
   "source": [
    "star = \"{*}\"\n",
    "previous_class_name = 0\n",
    "for i in np.arange(df_table.shape[0]):\n",
    "    class_name = df_table.iloc[i].class_name\n",
    "    keyword = df_table.iloc[i].keyword\n",
    "    frequency = df_table.iloc[i].keyword_frequency\n",
    "\n",
    "    if (class_name != previous_class_name) | (\n",
    "        previous_class_name == 0\n",
    "    ):  # first cell of class\n",
    "        keywords_per_class_str = (\n",
    "            \"{\" + str(df_table.iloc[i].keywords_per_class) + \"}\"\n",
    "        )\n",
    "        # class name\n",
    "        if class_name[0].isupper():\n",
    "            class_name_str = \"{\" + class_name + \"}\"\n",
    "        else:\n",
    "            class_name_str = \"{\" + class_name[0].upper() + class_name[1:] + \"}\"\n",
    "\n",
    "        # n_samples\n",
    "        n_samples_str = \"{\" + str(int(df_table.iloc[i].n_samples)) + \"}\"\n",
    "\n",
    "        print(\"\\midrule\")\n",
    "        print(\n",
    "            f\"\\multirow{keywords_per_class_str}{star}{class_name_str} & \\multirow{keywords_per_class_str}{star}{n_samples_str} & {keyword} & {frequency}    \\\\\\\\ \"\n",
    "        )\n",
    "\n",
    "    if class_name == previous_class_name:\n",
    "        print(f\"                      &   &  {keyword} & {frequency} \\\\\\\\ \")\n",
    "\n",
    "    previous_class_name = class_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
