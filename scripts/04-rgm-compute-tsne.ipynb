{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4170199-7901-42dd-b434-270b268fc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "\n",
    "from openTSNE import TSNE, affinity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path\n",
    "import distro\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c6055f-ab84-46c1-84f1-97fce3f41f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from plotting import plot_tsne_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb75c4d-f7cc-4e24-a9cc-d847c74babba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82cdefbf-dbd6-4c62-886f-bc0b0e06388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables/iclr24v2\")\n",
    "figures_path = Path(\"../results/figures\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33c65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"matplotlib_style.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c95a532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Rita Gonz치lez-M치rquez\n",
      "\n",
      "Last updated: 2024-04-12 09:05:29CEST\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.5\n",
      "IPython version      : 8.18.1\n",
      "\n",
      "openTSNE: 1.0.0\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 3.10.0-1160.el7.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 64\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: rgonzalesmarquez_GPU0-llm_gber7\n",
      "\n",
      "numpy          : 1.26.2\n",
      "jupyter_black  : 0.3.4\n",
      "pandas         : 2.1.3\n",
      "scipy          : 1.11.4\n",
      "black          : 23.11.0\n",
      "matplotlib     : 3.8.2\n",
      "distro         : 1.8.0\n",
      "openTSNE       : 1.0.0\n",
      "memory_profiler: 0.61.0\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n",
      "Ubuntu 22.04.3 LTS\n"
     ]
    }
   ],
   "source": [
    "%watermark -a 'Rita Gonz치lez-M치rquez' -t -d -tz -u -v -iv -w -m -h -p openTSNE\n",
    "print(distro.name(pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e365bc-8d5f-4bfc-beff-fa71ae05bb91",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9af5b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 70.9 ms, total: 247 ms\n",
      "Wall time: 182 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iclr2024 = pd.read_parquet(\n",
    "    data_path / \"iclr24v2.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "450820d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr2024.keywords = iclr2024.keywords.transform(lambda x: list(x))\n",
    "iclr2024.scores = iclr2024.scores.transform(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37cd0c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-Hhnslg</td>\n",
       "      <td>Prototypical Networks for Few-shot Learning</td>\n",
       "      <td>A recent approach to few-shot classification c...</td>\n",
       "      <td>Jake Snell, Kevin Swersky, Richard Zemel</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>[deep learning, transfer learning]</td>\n",
       "      <td>transfer learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-q5Pqxl</td>\n",
       "      <td>Machine Comprehension Using Match-LSTM and Ans...</td>\n",
       "      <td>Machine comprehension of text is an important ...</td>\n",
       "      <td>Shuohang Wang, Jing Jiang</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 7]</td>\n",
       "      <td>[natural language processing, deep learning]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16Jem9xe</td>\n",
       "      <td>Learning in Implicit Generative Models</td>\n",
       "      <td>Generative adversarial networks (GANs) provide...</td>\n",
       "      <td>Shakir Mohamed, Balaji Lakshminarayanan</td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[8, 7, 6]</td>\n",
       "      <td>[unsupervised learning]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16dGcqlx</td>\n",
       "      <td>Third Person Imitation Learning</td>\n",
       "      <td>Reinforcement learning (RL) makes it possible ...</td>\n",
       "      <td>Bradly C Stadie, Pieter Abbeel, Ilya Sutskever</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>B184E5qee</td>\n",
       "      <td>Improving Neural Language Models with a Contin...</td>\n",
       "      <td>We propose an extension to neural network lang...</td>\n",
       "      <td>Edouard Grave, Armand Joulin, Nicolas Usunier</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[7, 9, 5]</td>\n",
       "      <td>[natural language processing]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24440</th>\n",
       "      <td>2024</td>\n",
       "      <td>zxPDdw8koz</td>\n",
       "      <td>CLIP meets Model Zoo Experts: Pseudo-Supervisi...</td>\n",
       "      <td>Contrastive language image pretraining (CLIP) ...</td>\n",
       "      <td>Mohammadreza Salehi, Mehrdad Farajtabar, Maxwe...</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>[8, 3, 3, 3]</td>\n",
       "      <td>[contrastive learning, clip, distillation, den...</td>\n",
       "      <td>vision-language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24441</th>\n",
       "      <td>2024</td>\n",
       "      <td>zyBJodMrn5</td>\n",
       "      <td>On the generalization capacity of neural netwo...</td>\n",
       "      <td>The advent of the Transformer has led to the d...</td>\n",
       "      <td>Takuya Ito, Soham Dan, Mattia Rigotti, James K...</td>\n",
       "      <td>Accept (poster)</td>\n",
       "      <td>[8, 3, 6]</td>\n",
       "      <td>[compositional generalization, compositionalit...</td>\n",
       "      <td>out-of-distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24442</th>\n",
       "      <td>2024</td>\n",
       "      <td>zz61V8bIab</td>\n",
       "      <td>Stochastic Adversarial Networks for Multi-Doma...</td>\n",
       "      <td>Adversarial training has played a pivotal role...</td>\n",
       "      <td>Xu Wang, Yuan Wu</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>[5, 1, 5]</td>\n",
       "      <td>[multi-domain text classification, adversarial...</td>\n",
       "      <td>adversarial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24443</th>\n",
       "      <td>2024</td>\n",
       "      <td>zzqn5G9fjn</td>\n",
       "      <td>Breaking Physical and Linguistic Borders: Mult...</td>\n",
       "      <td>Pretrained large language models (LLMs) have e...</td>\n",
       "      <td>Wanru Zhao, Royson Lee, Yihong Chen, Xinchi Qi...</td>\n",
       "      <td>Accept (poster)</td>\n",
       "      <td>[5, 3, 1, 8]</td>\n",
       "      <td>[multilingual federated learning, natural lang...</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24444</th>\n",
       "      <td>2024</td>\n",
       "      <td>zzv4Bf50RW</td>\n",
       "      <td>Learning SO(3)-Invariant Correspondence via Po...</td>\n",
       "      <td>Establishing accurate dense 3D correspondences...</td>\n",
       "      <td>Chunghyun Park, Seungwook Kim, Jaesik Park, Mi...</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>[5, 5, 3, 5, 6]</td>\n",
       "      <td>[point cloud understanding, 3d dense correspon...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24445 rows 칑 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year          id                                              title  \\\n",
       "0      2017   B1-Hhnslg        Prototypical Networks for Few-shot Learning   \n",
       "1      2017   B1-q5Pqxl  Machine Comprehension Using Match-LSTM and Ans...   \n",
       "2      2017   B16Jem9xe             Learning in Implicit Generative Models   \n",
       "3      2017   B16dGcqlx                    Third Person Imitation Learning   \n",
       "4      2017   B184E5qee  Improving Neural Language Models with a Contin...   \n",
       "...     ...         ...                                                ...   \n",
       "24440  2024  zxPDdw8koz  CLIP meets Model Zoo Experts: Pseudo-Supervisi...   \n",
       "24441  2024  zyBJodMrn5  On the generalization capacity of neural netwo...   \n",
       "24442  2024  zz61V8bIab  Stochastic Adversarial Networks for Multi-Doma...   \n",
       "24443  2024  zzqn5G9fjn  Breaking Physical and Linguistic Borders: Mult...   \n",
       "24444  2024  zzv4Bf50RW  Learning SO(3)-Invariant Correspondence via Po...   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      A recent approach to few-shot classification c...   \n",
       "1      Machine comprehension of text is an important ...   \n",
       "2      Generative adversarial networks (GANs) provide...   \n",
       "3      Reinforcement learning (RL) makes it possible ...   \n",
       "4      We propose an extension to neural network lang...   \n",
       "...                                                  ...   \n",
       "24440  Contrastive language image pretraining (CLIP) ...   \n",
       "24441  The advent of the Transformer has led to the d...   \n",
       "24442  Adversarial training has played a pivotal role...   \n",
       "24443  Pretrained large language models (LLMs) have e...   \n",
       "24444  Establishing accurate dense 3D correspondences...   \n",
       "\n",
       "                                                 authors  \\\n",
       "0               Jake Snell, Kevin Swersky, Richard Zemel   \n",
       "1                              Shuohang Wang, Jing Jiang   \n",
       "2                Shakir Mohamed, Balaji Lakshminarayanan   \n",
       "3         Bradly C Stadie, Pieter Abbeel, Ilya Sutskever   \n",
       "4          Edouard Grave, Armand Joulin, Nicolas Usunier   \n",
       "...                                                  ...   \n",
       "24440  Mohammadreza Salehi, Mehrdad Farajtabar, Maxwe...   \n",
       "24441  Takuya Ito, Soham Dan, Mattia Rigotti, James K...   \n",
       "24442                                   Xu Wang, Yuan Wu   \n",
       "24443  Wanru Zhao, Royson Lee, Yihong Chen, Xinchi Qi...   \n",
       "24444  Chunghyun Park, Seungwook Kim, Jaesik Park, Mi...   \n",
       "\n",
       "                       decision           scores  \\\n",
       "0                        Reject        [6, 4, 5]   \n",
       "1               Accept (Poster)        [6, 6, 7]   \n",
       "2      Invite to Workshop Track        [8, 7, 6]   \n",
       "3               Accept (Poster)        [6, 5, 6]   \n",
       "4               Accept (Poster)        [7, 9, 5]   \n",
       "...                         ...              ...   \n",
       "24440                 Withdrawn     [8, 3, 3, 3]   \n",
       "24441           Accept (poster)        [8, 3, 6]   \n",
       "24442                 Withdrawn        [5, 1, 5]   \n",
       "24443           Accept (poster)     [5, 3, 1, 8]   \n",
       "24444                 Withdrawn  [5, 5, 3, 5, 6]   \n",
       "\n",
       "                                                keywords  \\\n",
       "0                     [deep learning, transfer learning]   \n",
       "1           [natural language processing, deep learning]   \n",
       "2                                [unsupervised learning]   \n",
       "3                                                     []   \n",
       "4                          [natural language processing]   \n",
       "...                                                  ...   \n",
       "24440  [contrastive learning, clip, distillation, den...   \n",
       "24441  [compositional generalization, compositionalit...   \n",
       "24442  [multi-domain text classification, adversarial...   \n",
       "24443  [multilingual federated learning, natural lang...   \n",
       "24444  [point cloud understanding, 3d dense correspon...   \n",
       "\n",
       "                       labels  \n",
       "0           transfer learning  \n",
       "1             language models  \n",
       "2                   unlabeled  \n",
       "3                   unlabeled  \n",
       "4             language models  \n",
       "...                       ...  \n",
       "24440  vision-language models  \n",
       "24441     out-of-distribution  \n",
       "24442             adversarial  \n",
       "24443         language models  \n",
       "24444               unlabeled  \n",
       "\n",
       "[24445 rows x 9 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b00bb7b5-0672-41b5-8957-9357c42c1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_iclr = iclr2024.labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e1f3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_iclr = np.load(variables_path / \"colors_iclr.npy\")\n",
    "\n",
    "pickle_in = open(variables_path / \"dict_label_to_color.pkl\", \"rb\")\n",
    "dict_label_to_color = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8b457",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ab971",
   "metadata": {},
   "source": [
    "## BERT-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049a206-297a-49d8-9c44-01ce125b3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"SimCSE\",\n",
    "    \"DeCLUTR-sci\",\n",
    "    \"SciNCL\",\n",
    "    \"SPECTER2\",\n",
    "    \"ST5\",\n",
    "    \"SBERT\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"princeton-nlp/unsup-simcse-bert-base-uncased\",\n",
    "    \"johngiorgi/declutr-sci-base\",\n",
    "    \"malteos/scincl\",\n",
    "    \"allenai/specter2_base\",\n",
    "    \"sentence-transformers/sentence-t5-base\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "]\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    # import\n",
    "    saving_path = Path(\"embeddings_\" + model_name.lower())\n",
    "\n",
    "    embedding_av = np.load(\n",
    "        variables_path / saving_path / \"embedding_abstracts_only_av.npy\"\n",
    "    )\n",
    "\n",
    "    if model_name != \"ST5\":\n",
    "        embedding_cls = np.load(\n",
    "            variables_path / saving_path / \"embedding_abstracts_only_cls.npy\"\n",
    "        )\n",
    "        embedding_sep = np.load(\n",
    "            variables_path / saving_path / \"embedding_abstracts_only_sep.npy\"\n",
    "        )\n",
    "\n",
    "        # t-SNE\n",
    "        tsne_cls = TSNE(verbose=True, random_state=42).fit(embedding_cls)\n",
    "        tsne_sep = TSNE(verbose=True, random_state=42).fit(embedding_sep)\n",
    "\n",
    "    tsne_av = TSNE(verbose=True, random_state=42).fit(embedding_av)\n",
    "\n",
    "    # save\n",
    "    if model_name != \"ST5\":\n",
    "        np.save(variables_path / saving_path / \"tsne_cls.npy\", tsne_cls)\n",
    "        np.save(variables_path / saving_path / \"tsne_sep.npy\", tsne_sep)\n",
    "    np.save(variables_path / saving_path / \"tsne_av.npy\", tsne_av)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227efa54-e06c-4d4c-8eb0-3768bfcffe83",
   "metadata": {},
   "source": [
    "### Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28e71ae-53fb-44d8-a76c-b95305ab8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_cohere\")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "embeddings_av = np.load(\n",
    "    variables_path / saving_path / \"embedding_abstracts_only_av.npy\",\n",
    ")\n",
    "\n",
    "tsne_av = TSNE(verbose=True, random_state=42).fit(embeddings_av)\n",
    "\n",
    "np.save(variables_path / saving_path / \"tsne_av\", tsne_av)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193fdad6-7315-47ec-b0d0-90773e5ffbb0",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a178a7-52e0-43be-a04f-45a9052376c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_openai\")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "embeddings_av = np.load(\n",
    "    variables_path / saving_path / \"embedding_abstracts_only_av.npy\",\n",
    ")\n",
    "\n",
    "tsne_av = TSNE(verbose=True, random_state=42).fit(embeddings_av)\n",
    "\n",
    "np.save(variables_path / saving_path / \"tsne_av\", tsne_av)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05665605",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cefa6d-d092-459f-ad37-14f57996d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "#tfidf_features = sp.sparse.load_npz(variables_path / \"tfidf_features.npz\")\n",
    "\n",
    "# svd_data = np.load(variables_path / \"svd_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15de472-de8a-4203-8800-a802edb55d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "A = affinity.PerplexityBasedNN(\n",
    "    tfidf_features,\n",
    "    verbose=True,\n",
    "    method=\"exact\",\n",
    "    random_state=42,\n",
    ")\n",
    "tsne_tfidf = TSNE(verbose=True, random_state=42).fit(\n",
    "    tfidf_features,\n",
    "    affinities=A,\n",
    "    initialization=svd_data[:, :2],\n",
    ")\n",
    "\n",
    "np.save(variables_path / \"tsne_tfidf\", tsne_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e702f56",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd_data = np.load(variables_path / \"svd_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "tsne_svd = TSNE(verbose=True, random_state=42).fit(svd_data[:, :100])\n",
    "\n",
    "np.save(variables_path / \"tsne_svd\", tsne_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c92e49-795c-48a6-83b9-5acb8a6928d8",
   "metadata": {},
   "source": [
    "## L2(SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf6ff2-5193-47f0-bd87-0e62a252277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svd_data = np.load(variables_path / \"svd_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb304171-f629-4d84-93a5-6f973f6320d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "tsne_L2_svd = TSNE(verbose=True, random_state=42).fit(\n",
    "    normalize(svd_data[:, :100], axis=1)\n",
    ")\n",
    "\n",
    "np.save(variables_path / \"tsne_L2_svd\", tsne_L2_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e8518",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6974755",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    len(model_names) + 1, 3, figsize=(9, 3 * (len(model_names) + 1)), dpi=200\n",
    ")\n",
    "rep = [\"av\", \"cls\", \"sep\"]\n",
    "acc_fontsize = 8\n",
    "for i in range(len(model_names) + 1):\n",
    "    for j in range(3):\n",
    "        if i == 0:\n",
    "            # load\n",
    "            ## tsnes\n",
    "            tsne_tfidf = np.load(variables_path / \"tsne_tfidf.npy\")\n",
    "            tsne_svd = np.load(variables_path / \"tsne_svd.npy\")\n",
    "            tsne_L2_svd = np.load(variables_path / \"tsne_L2_svd.npy\")\n",
    "\n",
    "            ## accuracies\n",
    "            knn_accuracy_tfidf = np.load(\n",
    "                variables_path / \"knn_accuracy_tfidf.npy\"\n",
    "            )\n",
    "            knn_accuracy_svd = np.load(variables_path / \"knn_accuracy_svd.npy\")\n",
    "            knn_accuracy_L2_svd = np.load(\n",
    "                variables_path / \"knn_accuracy_L2_svd.npy\"\n",
    "            )\n",
    "\n",
    "            knn_accuracy_tsne_tfidf = np.load(\n",
    "                variables_path / \"knn_accuracy_tsne_tfidf.npy\"\n",
    "            )\n",
    "            knn_accuracy_tsne_svd = np.load(\n",
    "                variables_path / \"knn_accuracy_tsne_svd.npy\"\n",
    "            )\n",
    "            knn_accuracy_tsne_L2_svd = np.load(\n",
    "                variables_path / \"knn_accuracy_tsne_L2_svd.npy\"\n",
    "            )\n",
    "\n",
    "            plot_tsne_colors(\n",
    "                tsne_tfidf, colors_iclr, ax=axs[i, 0], plot_type=\"subplot_3\"\n",
    "            )\n",
    "            axs[i, 0].set_title(f\"TF-IDF (d=44434)\", fontsize=15)\n",
    "\n",
    "            axs[i, 0].text(\n",
    "                0,\n",
    "                0.06,\n",
    "                f\"high-d: {knn_accuracy_tfidf*100:.1f}\",\n",
    "                transform=axs[i, 0].transAxes,\n",
    "                va=\"bottom\",\n",
    "                ha=\"left\",\n",
    "                size=acc_fontsize,\n",
    "            )\n",
    "            axs[i, 0].text(\n",
    "                0,\n",
    "                0.01,\n",
    "                f\"low-d:  {knn_accuracy_tsne_tfidf*100:.1f}\",\n",
    "                transform=axs[i, 0].transAxes,\n",
    "                va=\"bottom\",\n",
    "                ha=\"left\",\n",
    "                size=acc_fontsize,\n",
    "            )\n",
    "\n",
    "            plot_tsne_colors(\n",
    "                tsne_svd,\n",
    "                colors_iclr,\n",
    "                ax=axs[i, 1],\n",
    "                plot_type=\"subplot_3\",\n",
    "            )\n",
    "            axs[i, 1].set_title(\"SVD (d=100)\", fontsize=15)\n",
    "            axs[i, 1].text(\n",
    "                0,\n",
    "                0.06,\n",
    "                f\"high-d: {knn_accuracy_svd*100:.1f}\",\n",
    "                transform=axs[i, 1].transAxes,\n",
    "                va=\"bottom\",\n",
    "                ha=\"left\",\n",
    "                size=acc_fontsize,\n",
    "            )\n",
    "            axs[i, 1].text(\n",
    "                0,\n",
    "                0.01,\n",
    "                f\"low-d:  {knn_accuracy_tsne_svd*100:.1f}\",\n",
    "                transform=axs[i, 1].transAxes,\n",
    "                va=\"bottom\",\n",
    "                ha=\"left\",\n",
    "                size=acc_fontsize,\n",
    "            )\n",
    "\n",
    "            plot_tsne_colors(\n",
    "                tsne_L2_svd,\n",
    "                colors_iclr,\n",
    "                ax=axs[i, 2],\n",
    "                plot_type=\"subplot_3\",\n",
    "            )\n",
    "            axs[i, 2].set_title(\"L2(SVD) (d=100)\", fontsize=15)\n",
    "            axs[i, 2].text(\n",
    "                0,\n",
    "                0.06,\n",
    "                f\"high-d: {knn_accuracy_L2_svd*100:.1f}\",\n",
    "                transform=axs[i, 2].transAxes,\n",
    "                va=\"bottom\",\n",
    "                ha=\"left\",\n",
    "                size=acc_fontsize,\n",
    "            )\n",
    "            axs[i, 2].text(\n",
    "                0,\n",
    "                0.01,\n",
    "                f\"low-d:  {knn_accuracy_tsne_L2_svd*100:.1f}\",\n",
    "                transform=axs[i, 2].transAxes,\n",
    "                va=\"bottom\",\n",
    "                ha=\"left\",\n",
    "                size=acc_fontsize,\n",
    "            )\n",
    "        else:\n",
    "            # break\n",
    "            # load\n",
    "            ## tsnes\n",
    "            if (model_names[i - 1] == \"ST5\") & ((j == 1) | (j == 2)):\n",
    "                axs[i, j].axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                saving_path = Path(\"embeddings_\" + model_names[i - 1].lower())\n",
    "                tsne_name = \"tsne_\" + rep[j] + \".npy\"\n",
    "                tsne = np.load(variables_path / saving_path / tsne_name)\n",
    "\n",
    "                ## accuracies\n",
    "                saving_name = Path(\n",
    "                    \"knn_accuracy_\" + model_names[i - 1].lower() + \".npy\"\n",
    "                )\n",
    "                knn_acc_highd = np.load(variables_path / saving_name)\n",
    "\n",
    "                saving_name = Path(\n",
    "                    \"knn_accuracy_tsne_\" + model_names[i - 1].lower() + \".npy\"\n",
    "                )\n",
    "                knn_acc_lowd = np.load(variables_path / saving_name)\n",
    "\n",
    "                # plot\n",
    "                plot_tsne_colors(\n",
    "                    tsne, colors_iclr, ax=axs[i, j], plot_type=\"subplot_3\"\n",
    "                )\n",
    "                title = model_names[i - 1] + \" [\" + rep[j].upper() + \"]\"\n",
    "                axs[i, j].set_title(title, fontsize=15)\n",
    "\n",
    "                if model_names[i - 1] == \"ST5\":\n",
    "                    axs[i, j].text(\n",
    "                        0,\n",
    "                        0.06,\n",
    "                        f\"high-d: {knn_acc_highd*100:.1f}\",\n",
    "                        transform=axs[i, j].transAxes,\n",
    "                        va=\"bottom\",\n",
    "                        ha=\"left\",\n",
    "                        size=acc_fontsize,\n",
    "                    )\n",
    "                    axs[i, j].text(\n",
    "                        0,\n",
    "                        0.01,\n",
    "                        f\"low-d:  {knn_acc_lowd[0]*100:.1f}\",\n",
    "                        transform=axs[i, j].transAxes,\n",
    "                        va=\"bottom\",\n",
    "                        ha=\"left\",\n",
    "                        size=acc_fontsize,\n",
    "                    )\n",
    "                else:\n",
    "                    axs[i, j].text(\n",
    "                        0,\n",
    "                        0.06,\n",
    "                        f\"high-d: {knn_acc_highd[j]*100:.1f}\",\n",
    "                        transform=axs[i, j].transAxes,\n",
    "                        va=\"bottom\",\n",
    "                        ha=\"left\",\n",
    "                        size=acc_fontsize,\n",
    "                    )\n",
    "                    axs[i, j].text(\n",
    "                        0,\n",
    "                        0.01,\n",
    "                        f\"low-d:  {knn_acc_lowd[j]*100:.1f}\",\n",
    "                        transform=axs[i, j].transAxes,\n",
    "                        va=\"bottom\",\n",
    "                        ha=\"left\",\n",
    "                        size=acc_fontsize,\n",
    "                    )\n",
    "\n",
    "fig.savefig(figures_path / \"tmp\" / \"tsne_embeddings_iclr_with_knn_accs_v2.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
