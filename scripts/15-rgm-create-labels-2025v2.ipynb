{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import glasbey\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path\n",
    "import distro\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables/iclr25v2\")\n",
    "figures_path = Path(\"../results/figures\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs01/berens/user/rgonzalesmarquez'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL FIX TO PATH ISSUE FROM VSCODE\n",
    "nb_path = Path(\"phd/iclr-dataset/scripts\")\n",
    "assert nb_path.exists(), \"The path does not exist\"\n",
    "\n",
    "variables_path = (nb_path / variables_path).resolve(strict=True)\n",
    "figures_path = (nb_path / figures_path).resolve(strict=True)\n",
    "data_path = (nb_path / data_path).resolve(strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/phd/iclr-dataset/results/variables/iclr25v2\n"
     ]
    }
   ],
   "source": [
    "print(variables_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use((nb_path / Path(\"matplotlib_style.txt\")).resolve(strict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Rita Gonz치lez-M치rquez\n",
      "\n",
      "Last updated: 2025-03-20 14:18:00CET\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.4\n",
      "IPython version      : 8.31.0\n",
      "\n",
      "transformers: 4.45.2\n",
      "openTSNE    : 1.0.2\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 4.18.0-553.el8_10.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 64\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: rgonzalesmarquez_GPU0-llm_gber7\n",
      "\n",
      "distro         : 1.9.0\n",
      "glasbey        : 0.2.1\n",
      "seaborn        : 0.13.2\n",
      "matplotlib     : 3.9.2\n",
      "memory_profiler: 0.61.0\n",
      "pandas         : 2.2.3\n",
      "numpy          : 1.26.4\n",
      "jupyter_black  : 0.4.0\n",
      "\n",
      "Watermark: 2.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a 'Rita Gonz치lez-M치rquez' -t -d -tz -u -v -iv -w -m -h -p transformers,openTSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "ICLR new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 269 ms, sys: 92.9 ms, total: 362 ms\n",
      "Wall time: 346 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iclr = pd.read_parquet(\n",
    "    data_path / \"iclr25v2.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr.keywords = iclr.keywords.transform(lambda x: list(x))\n",
    "iclr.scores = iclr.scores.transform(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34519</th>\n",
       "      <td>2025</td>\n",
       "      <td>zxO4WuVGns</td>\n",
       "      <td>Inverse decision-making using neural amortized...</td>\n",
       "      <td>Bayesian observer and actor models have provid...</td>\n",
       "      <td>Dominik Straub, Tobias F. Niehues, Jan Peters,...</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>[Bayesian actor models, perception and action,...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34520</th>\n",
       "      <td>2025</td>\n",
       "      <td>zxbQLztmwb</td>\n",
       "      <td>Emergent Symbol-Like Number Variables in Artif...</td>\n",
       "      <td>There is an open question of what types of num...</td>\n",
       "      <td>Satchel Grant, Noah Goodman, James Lloyd McCle...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[3, 5, 6, 5]</td>\n",
       "      <td>[mechanistic interpretability, numeric cogniti...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>2025</td>\n",
       "      <td>zxqdVo9FjY</td>\n",
       "      <td>Generalization for Least Squares Regression wi...</td>\n",
       "      <td>Random matrix theory has proven to be a valuab...</td>\n",
       "      <td>Jiping Li, Rishi Sonthalia</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[5, 3, 5, 5, 6]</td>\n",
       "      <td>[Generalization, Random Matrix Theory, Spiked ...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34522</th>\n",
       "      <td>2025</td>\n",
       "      <td>zyGrziIVdE</td>\n",
       "      <td>Exploration by Running Away from the Past</td>\n",
       "      <td>The ability to explore efficiently and effecti...</td>\n",
       "      <td>Paul-Antoine LE TOLGUENEC, Yann Besse, Florent...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[3, 3, 5, 3]</td>\n",
       "      <td>[Reinforcement Learning, Exploration, Deep Lea...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34523</th>\n",
       "      <td>2025</td>\n",
       "      <td>zzR1Uskhj0</td>\n",
       "      <td>High Probability Bounds for Cross-Learning Con...</td>\n",
       "      <td>Motivated by applications in online bidding an...</td>\n",
       "      <td>Ruiyuan Huang, Zengfeng Huang</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[5, 5, 8, 6, 6]</td>\n",
       "      <td>[contextual bandits, cross-learning, high-prob...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year          id                                              title  \\\n",
       "34519  2025  zxO4WuVGns  Inverse decision-making using neural amortized...   \n",
       "34520  2025  zxbQLztmwb  Emergent Symbol-Like Number Variables in Artif...   \n",
       "34521  2025  zxqdVo9FjY  Generalization for Least Squares Regression wi...   \n",
       "34522  2025  zyGrziIVdE          Exploration by Running Away from the Past   \n",
       "34523  2025  zzR1Uskhj0  High Probability Bounds for Cross-Learning Con...   \n",
       "\n",
       "                                                abstract  \\\n",
       "34519  Bayesian observer and actor models have provid...   \n",
       "34520  There is an open question of what types of num...   \n",
       "34521  Random matrix theory has proven to be a valuab...   \n",
       "34522  The ability to explore efficiently and effecti...   \n",
       "34523  Motivated by applications in online bidding an...   \n",
       "\n",
       "                                                 authors         decision  \\\n",
       "34519  Dominik Straub, Tobias F. Niehues, Jan Peters,...  Accept (Poster)   \n",
       "34520  Satchel Grant, Noah Goodman, James Lloyd McCle...           Reject   \n",
       "34521                         Jiping Li, Rishi Sonthalia           Reject   \n",
       "34522  Paul-Antoine LE TOLGUENEC, Yann Besse, Florent...           Reject   \n",
       "34523                      Ruiyuan Huang, Zengfeng Huang           Reject   \n",
       "\n",
       "                scores                                           keywords  \\\n",
       "34519        [6, 6, 6]  [Bayesian actor models, perception and action,...   \n",
       "34520     [3, 5, 6, 5]  [mechanistic interpretability, numeric cogniti...   \n",
       "34521  [5, 3, 5, 5, 6]  [Generalization, Random Matrix Theory, Spiked ...   \n",
       "34522     [3, 3, 5, 3]  [Reinforcement Learning, Exploration, Deep Lea...   \n",
       "34523  [5, 5, 8, 6, 6]  [contextual bandits, cross-learning, high-prob...   \n",
       "\n",
       "          labels  \n",
       "34519  unlabeled  \n",
       "34520  unlabeled  \n",
       "34521  unlabeled  \n",
       "34522  unlabeled  \n",
       "34523  unlabeled  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr[\"keywords\"] = iclr[\"keywords\"].apply(lambda x: [s.lower() for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34519</th>\n",
       "      <td>2025</td>\n",
       "      <td>zxO4WuVGns</td>\n",
       "      <td>Inverse decision-making using neural amortized...</td>\n",
       "      <td>Bayesian observer and actor models have provid...</td>\n",
       "      <td>Dominik Straub, Tobias F. Niehues, Jan Peters,...</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>[bayesian actor models, perception and action,...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34520</th>\n",
       "      <td>2025</td>\n",
       "      <td>zxbQLztmwb</td>\n",
       "      <td>Emergent Symbol-Like Number Variables in Artif...</td>\n",
       "      <td>There is an open question of what types of num...</td>\n",
       "      <td>Satchel Grant, Noah Goodman, James Lloyd McCle...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[3, 5, 6, 5]</td>\n",
       "      <td>[mechanistic interpretability, numeric cogniti...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>2025</td>\n",
       "      <td>zxqdVo9FjY</td>\n",
       "      <td>Generalization for Least Squares Regression wi...</td>\n",
       "      <td>Random matrix theory has proven to be a valuab...</td>\n",
       "      <td>Jiping Li, Rishi Sonthalia</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[5, 3, 5, 5, 6]</td>\n",
       "      <td>[generalization, random matrix theory, spiked ...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34522</th>\n",
       "      <td>2025</td>\n",
       "      <td>zyGrziIVdE</td>\n",
       "      <td>Exploration by Running Away from the Past</td>\n",
       "      <td>The ability to explore efficiently and effecti...</td>\n",
       "      <td>Paul-Antoine LE TOLGUENEC, Yann Besse, Florent...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[3, 3, 5, 3]</td>\n",
       "      <td>[reinforcement learning, exploration, deep lea...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34523</th>\n",
       "      <td>2025</td>\n",
       "      <td>zzR1Uskhj0</td>\n",
       "      <td>High Probability Bounds for Cross-Learning Con...</td>\n",
       "      <td>Motivated by applications in online bidding an...</td>\n",
       "      <td>Ruiyuan Huang, Zengfeng Huang</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[5, 5, 8, 6, 6]</td>\n",
       "      <td>[contextual bandits, cross-learning, high-prob...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year          id                                              title  \\\n",
       "34519  2025  zxO4WuVGns  Inverse decision-making using neural amortized...   \n",
       "34520  2025  zxbQLztmwb  Emergent Symbol-Like Number Variables in Artif...   \n",
       "34521  2025  zxqdVo9FjY  Generalization for Least Squares Regression wi...   \n",
       "34522  2025  zyGrziIVdE          Exploration by Running Away from the Past   \n",
       "34523  2025  zzR1Uskhj0  High Probability Bounds for Cross-Learning Con...   \n",
       "\n",
       "                                                abstract  \\\n",
       "34519  Bayesian observer and actor models have provid...   \n",
       "34520  There is an open question of what types of num...   \n",
       "34521  Random matrix theory has proven to be a valuab...   \n",
       "34522  The ability to explore efficiently and effecti...   \n",
       "34523  Motivated by applications in online bidding an...   \n",
       "\n",
       "                                                 authors         decision  \\\n",
       "34519  Dominik Straub, Tobias F. Niehues, Jan Peters,...  Accept (Poster)   \n",
       "34520  Satchel Grant, Noah Goodman, James Lloyd McCle...           Reject   \n",
       "34521                         Jiping Li, Rishi Sonthalia           Reject   \n",
       "34522  Paul-Antoine LE TOLGUENEC, Yann Besse, Florent...           Reject   \n",
       "34523                      Ruiyuan Huang, Zengfeng Huang           Reject   \n",
       "\n",
       "                scores                                           keywords  \\\n",
       "34519        [6, 6, 6]  [bayesian actor models, perception and action,...   \n",
       "34520     [3, 5, 6, 5]  [mechanistic interpretability, numeric cogniti...   \n",
       "34521  [5, 3, 5, 5, 6]  [generalization, random matrix theory, spiked ...   \n",
       "34522     [3, 3, 5, 3]  [reinforcement learning, exploration, deep lea...   \n",
       "34523  [5, 5, 8, 6, 6]  [contextual bandits, cross-learning, high-prob...   \n",
       "\n",
       "          labels  \n",
       "34519  unlabeled  \n",
       "34520  unlabeled  \n",
       "34521  unlabeled  \n",
       "34522  unlabeled  \n",
       "34523  unlabeled  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34524, 9)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign new labels\n",
    "Labels are the same as for the 25v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists of keywords and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keyword_to_label_25 = {\n",
    "    ###### ADVERSARIAL\n",
    "    \"adversarial\": \"adversarial\",\n",
    "    \"adversarial attack\": \"adversarial\",\n",
    "    \"adversarial attacks\": \"adversarial\",\n",
    "    \"adversarial defense\": \"adversarial\",\n",
    "    \"adversarial examples\": \"adversarial\",\n",
    "    \"adversarial example\": \"adversarial\",  # NEW 2025\n",
    "    \"adversarial learning\": \"adversarial\",\n",
    "    \"adversarial machine learning\": \"adversarial\",\n",
    "    \"adversarial robustness\": \"adversarial\",\n",
    "    \"adversarial training\": \"adversarial\",\n",
    "    ###### TRANSFORMERS\n",
    "    \"attention\": \"transformers\",\n",
    "    \"attention mechanism\": \"transformers\",\n",
    "    \"transformer\": \"transformers\",\n",
    "    \"transformers\": \"transformers\",\n",
    "    \"self-attention\": \"transformers\",\n",
    "    ###### AUTOENCODERS\n",
    "    \"autoencoder\": \"autoencoders\",\n",
    "    \"autoencoders\": \"autoencoders\",\n",
    "    \"vae\": \"autoencoders\",\n",
    "    \"vaes\": \"autoencoders\",  # NEW 2025\n",
    "    \"variational autoencoder\": \"autoencoders\",\n",
    "    \"variational autoencoders\": \"autoencoders\",\n",
    "    ######\n",
    "    \"anomaly detection\": \"anomaly detection\",\n",
    "    ###### CAUSALITY\n",
    "    \"causal discovery\": \"causality\",\n",
    "    \"causal inference\": \"causality\",\n",
    "    \"causality\": \"causality\",\n",
    "    ######\n",
    "    \"clustering\": \"clustering\",\n",
    "    ###### COMPRESSION\n",
    "    \"compression\": \"compression\",\n",
    "    \"model compression\": \"compression\",\n",
    "    ######\n",
    "    \"object detection\": \"object detection\",\n",
    "    \"semantic segmentation\": \"object detection\",  # NEW 2025\n",
    "    # ######  -- MOVED TO SSL IN 2025\n",
    "    # \"contrastive learning\": \"contrastive learning\",\n",
    "    ###### CNNs\n",
    "    \"convolutional neural network\": \"CNNs\",\n",
    "    \"convolutional neural networks\": \"CNNs\",\n",
    "    \"cnn\": \"CNNs\",\n",
    "    \"cnns\": \"CNNs\",  # NEW 2025\n",
    "    ###### DIFFUSION MODELS\n",
    "    \"diffusion\": \"diffusion models\",\n",
    "    \"diffusion model\": \"diffusion models\",\n",
    "    \"diffusion models\": \"diffusion models\",\n",
    "    ###### EXPLAINABILITY\n",
    "    \"explainability\": \"explainability\",\n",
    "    \"explainable ai\": \"explainability\",\n",
    "    ######\n",
    "    \"interpretability\": \"interpretability\",\n",
    "    ######\n",
    "    \"fairness\": \"fairness\",\n",
    "    ######\n",
    "    \"federated learning\": \"federated learning\",\n",
    "    ###### GANs\n",
    "    \"generative adversarial network\": \"GANs\",\n",
    "    \"generative adversarial networks\": \"GANs\",\n",
    "    \"gan\": \"GANs\",\n",
    "    \"gans\": \"GANs\",\n",
    "    ###### GRAPHS\n",
    "    \"graph\": \"graphs\",\n",
    "    \"graphs\": \"graphs\",  # NEW 2025\n",
    "    \"graph neural network\": \"graphs\",\n",
    "    \"graph neural networks\": \"graphs\",\n",
    "    \"graph representation learning\": \"graphs\",\n",
    "    \"gnn\": \"graphs\",  # NEW 2025\n",
    "    \"gnns\": \"graphs\",\n",
    "    \"node classification\": \"graphs\",\n",
    "    ###### LLMs\n",
    "    \"llm\": \"LLMs\",\n",
    "    \"large language model\": \"LLMs\",\n",
    "    \"large language models\": \"LLMs\",\n",
    "    \"prompting\": \"LLMs\",\n",
    "    \"bert\": \"LLMs\",  # NEW 2025\n",
    "    \"llms\": \"LLMs\",  # NEW 2025\n",
    "    \"text generation\": \"LLMs\",  # NEW 2025\n",
    "    ######\n",
    "    \"knowledge distillation\": \"knowledge distillation\",\n",
    "    ###### LANGUAGE MODELS\n",
    "    \"natural language processing\": \"language models\",\n",
    "    \"nlp\": \"language models\",\n",
    "    \"language model\": \"language models\",\n",
    "    \"language models\": \"language models\",\n",
    "    \"language modeling\": \"language models\",\n",
    "    \"machine translation\": \"language models\",\n",
    "    \"question answering\": \"language models\",\n",
    "    \"reasoning\": \"language models\",\n",
    "    ###### META LEARNING\n",
    "    \"meta learning\": \"meta learning\",\n",
    "    \"meta-learning\": \"meta learning\",\n",
    "    ###### PRUNING\n",
    "    \"network pruning\": \"pruning\",\n",
    "    \"pruning\": \"pruning\",\n",
    "    ######\n",
    "    \"neural architecture search\": \"neural architecture search\",\n",
    "    ######\n",
    "    \"optimal transport\": \"optimal transport\",\n",
    "    ###### OPTIMIZATION\n",
    "    \"stochastic gradient descent\": \"optimization\",\n",
    "    \"stochastic optimization\": \"optimization\",\n",
    "    \"sgd\": \"optimization\",\n",
    "    \"optimization\": \"optimization\",\n",
    "    \"non-convex optimization\": \"optimization\",\n",
    "    \"convex optimization\": \"optimization\",\n",
    "    \"gradient descent\": \"optimization\",\n",
    "    \"combinatorial optimization\": \"optimization\",\n",
    "    \"bayesian optimization\": \"optimization\",\n",
    "    ###### OUT-OF-DISTRIBUTION\n",
    "    \"out-of-distribution\": \"out-of-distribution\",\n",
    "    \"out-of-distribution detection\": \"out-of-distribution\",\n",
    "    \"out-of-distribution generalization\": \"out-of-distribution\",\n",
    "    \"distribution shift\": \"out-of-distribution\",\n",
    "    ###### PRIVACY\n",
    "    \"differential privacy\": \"privacy\",\n",
    "    \"privacy\": \"privacy\",\n",
    "    ###### RNNs\n",
    "    \"rnn\": \"RNNs\",\n",
    "    \"rnns\": \"RNNs\",  # NEW 2025\n",
    "    \"recurrent neural network\": \"RNNs\",\n",
    "    \"recurrent neural networks\": \"RNNs\",\n",
    "    \"lstm\": \"RNNs\",\n",
    "    ###### REINFORCEMENT LEARNING\n",
    "    \"reinforcement learning\": \"RL\",\n",
    "    \"deep reinforcement learning\": \"RL\",\n",
    "    ######\n",
    "    \"active learning\": \"active learning\",\n",
    "    ######\n",
    "    \"model-based reinforcement learning\": \"model-based RL\",\n",
    "    ######\n",
    "    \"multi-agent reinforcement learning\": \"multi-agent RL\",\n",
    "    \"multi-agent\": \"multi-agent RL\",  # NEW 2025\n",
    "    ######\n",
    "    \"multi-task learning\": \"multi-task learning\",\n",
    "    ######\n",
    "    \"imitation learning\": \"imitation learning\",\n",
    "    ###### OFFLINE RL\n",
    "    \"offline reinforcement learning\": \"offline RL\",\n",
    "    \"offline rl\": \"offline RL\",\n",
    "    ###### CONTINUAL LEARNING\n",
    "    \"continual learning\": \"continual learning\",\n",
    "    \"lifelong learning\": \"continual learning\",\n",
    "    ######\n",
    "    \"in-context learning\": \"in-context learning\",\n",
    "    ######\n",
    "    \"few-shot learning\": \"few-shot learning\",\n",
    "    ######\n",
    "    \"robustness\": \"robustness\",\n",
    "    ###### SELF-SUPERVISED LEARNING\n",
    "    \"self-supervised learning\": \"self-supervised learning\",\n",
    "    \"contrastive learning\": \"self-supervised learning\",\n",
    "    ######\n",
    "    \"semi-supervised learning\": \"semi-supervised learning\",\n",
    "    ###### TIME SERIES\n",
    "    \"time series\": \"time series\",\n",
    "    \"time series forecasting\": \"time series\",\n",
    "    ###### TRANSFER LEARNING\n",
    "    \"transfer learning\": \"transfer learning\",\n",
    "    \"domain adaptation\": \"transfer learning\",\n",
    "    \"domain generalization\": \"transfer learning\",\n",
    "    ###### ViTs\n",
    "    \"vision transformer\": \"ViTs\",\n",
    "    \"vision transformers\": \"ViTs\",\n",
    "    ###### VISION-LANGUAGE MODELS\n",
    "    \"vision-language models\": \"vision-language models\",\n",
    "    \"vision-language model\": \"vision-language models\",  # NEW 2025\n",
    "    \"clip\": \"vision-language models\",\n",
    "    ###### ---------------------------- NEW 2025 --------------------------------\n",
    "    #### SAFETY\n",
    "    \"ai safety\": \"safety\",\n",
    "    \"safety\": \"safety\",\n",
    "    #### ALIGNMENT\n",
    "    \"alignment\": \"alignment\",\n",
    "    \"rlhf\": \"alignment\",\n",
    "    #####\n",
    "    \"autonomous driving\": \"autonomous driving\",\n",
    "    #### CODE GENERATION\n",
    "    \"code generation\": \"code generation\",\n",
    "    \"program synthesis\": \"code generation\",\n",
    "    #### KNOWLEDGE GRAPHS\n",
    "    \"knowledge graph\": \"knowledge graphs\",\n",
    "    \"knowledge graphs\": \"knowledge graphs\",\n",
    "    # ####\n",
    "    \"neuroscience\": \"neuroscience\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# keywords:  134\n",
      "# labels:  50\n"
     ]
    }
   ],
   "source": [
    "print(\"# keywords: \", len(np.unique(list(dict_keyword_to_label_25.keys()))))\n",
    "print(\"# labels: \", len(np.unique(list(dict_keyword_to_label_25.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025\n",
    "unique_keywords_25, counts_25 = np.unique(\n",
    "    np.hstack(iclr.keywords), return_counts=True\n",
    ")\n",
    "\n",
    "n = 200\n",
    "unique_keywords_25_sorted = unique_keywords_25[np.flip(np.argsort(counts_25))]\n",
    "counts_25_sorted = np.flip(np.sort(counts_25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keywords_frequencies_25 = dict(\n",
    "    zip(unique_keywords_25_sorted, counts_25_sorted)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('adversarial', 67),\n",
       "  ('adversarial attack', 151),\n",
       "  ('adversarial attacks', 146),\n",
       "  ('adversarial defense', 62),\n",
       "  ('adversarial examples', 210),\n",
       "  ('adversarial example', 34),\n",
       "  ('adversarial learning', 99),\n",
       "  ('adversarial machine learning', 64),\n",
       "  ('adversarial robustness', 296),\n",
       "  ('adversarial training', 250)],\n",
       " [('attention', 241),\n",
       "  ('attention mechanism', 74),\n",
       "  ('transformer', 495),\n",
       "  ('transformers', 403),\n",
       "  ('self-attention', 97)],\n",
       " [('autoencoder', 73),\n",
       "  ('autoencoders', 61),\n",
       "  ('vae', 82),\n",
       "  ('vaes', 10),\n",
       "  ('variational autoencoder', 106),\n",
       "  ('variational autoencoders', 89)],\n",
       " [('anomaly detection', 151)],\n",
       " [('causal discovery', 87), ('causal inference', 151), ('causality', 117)],\n",
       " [('clustering', 157)],\n",
       " [('compression', 156), ('model compression', 173)],\n",
       " [('object detection', 150), ('semantic segmentation', 111)],\n",
       " [('convolutional neural network', 81),\n",
       "  ('convolutional neural networks', 138),\n",
       "  ('cnn', 106),\n",
       "  ('cnns', 24)],\n",
       " [('diffusion', 149), ('diffusion model', 371), ('diffusion models', 566)],\n",
       " [('explainability', 194), ('explainable ai', 138)],\n",
       " [('interpretability', 556)],\n",
       " [('fairness', 262)],\n",
       " [('federated learning', 628)],\n",
       " [('generative adversarial network', 75),\n",
       "  ('generative adversarial networks', 197),\n",
       "  ('gan', 176),\n",
       "  ('gans', 97)],\n",
       " [('graph', 63),\n",
       "  ('graphs', 42),\n",
       "  ('graph neural network', 322),\n",
       "  ('graph neural networks', 751),\n",
       "  ('graph representation learning', 108),\n",
       "  ('gnn', 84),\n",
       "  ('gnns', 26),\n",
       "  ('node classification', 77)],\n",
       " [('llm', 386),\n",
       "  ('large language model', 623),\n",
       "  ('large language models', 1188),\n",
       "  ('prompting', 65),\n",
       "  ('bert', 84),\n",
       "  ('llms', 187),\n",
       "  ('text generation', 72)],\n",
       " [('knowledge distillation', 279)],\n",
       " [('natural language processing', 487),\n",
       "  ('nlp', 206),\n",
       "  ('language model', 162),\n",
       "  ('language models', 293),\n",
       "  ('language modeling', 104),\n",
       "  ('machine translation', 103),\n",
       "  ('question answering', 79),\n",
       "  ('reasoning', 198)],\n",
       " [('meta learning', 135), ('meta-learning', 328)],\n",
       " [('network pruning', 52), ('pruning', 167)],\n",
       " [('neural architecture search', 199)],\n",
       " [('optimal transport', 231)],\n",
       " [('stochastic gradient descent', 88),\n",
       "  ('stochastic optimization', 79),\n",
       "  ('sgd', 100),\n",
       "  ('optimization', 539),\n",
       "  ('non-convex optimization', 83),\n",
       "  ('convex optimization', 75),\n",
       "  ('gradient descent', 107),\n",
       "  ('combinatorial optimization', 100),\n",
       "  ('bayesian optimization', 92)],\n",
       " [('out-of-distribution', 68),\n",
       "  ('out-of-distribution detection', 130),\n",
       "  ('out-of-distribution generalization', 77),\n",
       "  ('distribution shift', 131)],\n",
       " [('differential privacy', 211), ('privacy', 154)],\n",
       " [('rnn', 76),\n",
       "  ('rnns', 30),\n",
       "  ('recurrent neural network', 53),\n",
       "  ('recurrent neural networks', 128),\n",
       "  ('lstm', 72)],\n",
       " [('reinforcement learning', 2028), ('deep reinforcement learning', 343)],\n",
       " [('active learning', 179)],\n",
       " [('model-based reinforcement learning', 130)],\n",
       " [('multi-agent reinforcement learning', 207), ('multi-agent', 69)],\n",
       " [('multi-task learning', 187)],\n",
       " [('imitation learning', 219)],\n",
       " [('offline reinforcement learning', 205), ('offline rl', 71)],\n",
       " [('continual learning', 448), ('lifelong learning', 97)],\n",
       " [('in-context learning', 229)],\n",
       " [('few-shot learning', 242)],\n",
       " [('robustness', 524)],\n",
       " [('self-supervised learning', 586), ('contrastive learning', 440)],\n",
       " [('semi-supervised learning', 272)],\n",
       " [('time series', 192), ('time series forecasting', 102)],\n",
       " [('transfer learning', 461),\n",
       "  ('domain adaptation', 223),\n",
       "  ('domain generalization', 149)],\n",
       " [('vision transformer', 116), ('vision transformers', 61)],\n",
       " [('vision-language models', 111),\n",
       "  ('vision-language model', 47),\n",
       "  ('clip', 119)],\n",
       " [('ai safety', 99), ('safety', 123)],\n",
       " [('alignment', 207), ('rlhf', 103)],\n",
       " [('autonomous driving', 97)],\n",
       " [('code generation', 93), ('program synthesis', 72)],\n",
       " [('knowledge graph', 69), ('knowledge graphs', 43)],\n",
       " [('neuroscience', 120)]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_keywords_25 = [\n",
    "    dict_keywords_frequencies_25[key]\n",
    "    for key in dict_keyword_to_label_25.keys()\n",
    "]\n",
    "\n",
    "list_to_group = list(\n",
    "    zip(\n",
    "        dict_keyword_to_label_25.values(),\n",
    "        dict_keyword_to_label_25.keys(),\n",
    "        freqs_keywords_25,\n",
    "    )\n",
    ")\n",
    "key_func = lambda x: x[0]\n",
    "\n",
    "final_keywords_groups_25 = []\n",
    "for key, group in itertools.groupby(list_to_group, key_func):\n",
    "    final_keywords_groups_25.append([elem[1:] for elem in group])\n",
    "\n",
    "final_keywords_groups_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def assign_labels_and_colors(\n",
    "    data, keywords_and_freqs, dict_keyword_to_label, dict_color_legend=None\n",
    "):\n",
    "    \"\"\"Assign labels and colors from list with lists of keywords.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: list of lists, len (n_samples)\n",
    "        List with lists of keywords for every paper.\n",
    "    keywords_and_freqs: list of lists, len (n_labels)\n",
    "        List of keywords groups. Contains all keywords and frequencies, with sublists of subgroups of keywords.\n",
    "    dict_keyword_to_label: dict\n",
    "        Dictionary assigning to each keyword its label (e.g. to all keywords in same subgroup same label).\n",
    "    dict_color_legend: dict, len (n_labels)\n",
    "        Dictionary assigning to each label a color.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels: array, shape (n_samples,)\n",
    "        Label for each paper.\n",
    "    colors: array, shape (n_samples,)\n",
    "        Color for each paper.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare dict_freqs\n",
    "    dict_freqs = dict(list(itertools.chain.from_iterable(keywords_and_freqs)))\n",
    "    dict_freqs[\"unlabeled\"] = (\n",
    "        1e9  # assign very large value to unlabeled for argmax\n",
    "    )\n",
    "\n",
    "    # clean empty lists of keywords from the data\n",
    "    data_without_empty = [\n",
    "        [\"unlabeled\"] if elem == [] else elem for elem in data\n",
    "    ]\n",
    "\n",
    "    # choose keywords for each paper\n",
    "    chosen_keywords = []\n",
    "    for list_keywords in data_without_empty:\n",
    "        list_keywords_filtered = [\n",
    "            elem if elem in set(dict_freqs.keys()) else \"unlabeled\"\n",
    "            for elem in list_keywords\n",
    "        ]\n",
    "\n",
    "        freqs = np.vectorize(dict_freqs.get)(list_keywords_filtered)\n",
    "\n",
    "        chosen_keyword = list_keywords_filtered[np.argmin(freqs)]\n",
    "        chosen_keywords.append(chosen_keyword)\n",
    "\n",
    "    chosen_keywords = np.array(chosen_keywords)\n",
    "\n",
    "    # map chosen keywords to labels\n",
    "    dict_keyword_to_label[\"unlabeled\"] = \"unlabeled\"\n",
    "    labels = np.vectorize(dict_keyword_to_label.get)(chosen_keywords)\n",
    "\n",
    "    # colors\n",
    "    colors = np.vectorize(dict_color_legend.get)(labels)\n",
    "\n",
    "    return labels, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\n",
    "    \"/gpfs01/berens/user/rgonzalesmarquez/phd/iclr-dataset/results/variables/iclr25v1/dict_label_to_color.pkl\",\n",
    "    \"rb\",\n",
    ")\n",
    "dict_label_to_color_25 = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 936 ms, sys: 176 ms, total: 1.11 s\n",
      "Wall time: 938 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels_iclr, colors_iclr = assign_labels_and_colors(\n",
    "    iclr.keywords.to_list(),\n",
    "    final_keywords_groups_25,\n",
    "    dict_keyword_to_label_25,\n",
    "    dict_label_to_color_25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "np.save(variables_path / \"labels_iclr\", labels_iclr)\n",
    "np.save(variables_path / \"colors_iclr\", colors_iclr)\n",
    "\n",
    "f = open(variables_path / \"dict_label_to_color.pkl\", \"wb\")\n",
    "pickle.dump(dict_label_to_color_25, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of unlabeled papers:  45.278646738500754\n",
      "Number of unlabeled papers:  15632\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of unlabeled papers: \",\n",
    "    np.sum(labels_iclr == \"unlabeled\") / len(labels_iclr) * 100,\n",
    ")\n",
    "print(\n",
    "    \"Number of unlabeled papers: \",\n",
    "    np.sum(labels_iclr == \"unlabeled\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers without any keywords:  6.172517668868034\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Papers without any keywords: \",\n",
    "    np.sum([1 if elem == [] else 0 for elem in iclr.keywords])\n",
    "    / len(labels_iclr)\n",
    "    * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column to dataframe and resave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-Hhnslg</td>\n",
       "      <td>Prototypical Networks for Few-shot Learning</td>\n",
       "      <td>A recent approach to few-shot classification c...</td>\n",
       "      <td>Jake Snell, Kevin Swersky, Richard Zemel</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>[deep learning, transfer learning]</td>\n",
       "      <td>transfer learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-q5Pqxl</td>\n",
       "      <td>Machine Comprehension Using Match-LSTM and Ans...</td>\n",
       "      <td>Machine comprehension of text is an important ...</td>\n",
       "      <td>Shuohang Wang, Jing Jiang</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 7]</td>\n",
       "      <td>[natural language processing, deep learning]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16Jem9xe</td>\n",
       "      <td>Learning in Implicit Generative Models</td>\n",
       "      <td>Generative adversarial networks (GANs) provide...</td>\n",
       "      <td>Shakir Mohamed, Balaji Lakshminarayanan</td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[8, 7, 6]</td>\n",
       "      <td>[unsupervised learning]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16dGcqlx</td>\n",
       "      <td>Third Person Imitation Learning</td>\n",
       "      <td>Reinforcement learning (RL) makes it possible ...</td>\n",
       "      <td>Bradly C Stadie, Pieter Abbeel, Ilya Sutskever</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>B184E5qee</td>\n",
       "      <td>Improving Neural Language Models with a Contin...</td>\n",
       "      <td>We propose an extension to neural network lang...</td>\n",
       "      <td>Edouard Grave, Armand Joulin, Nicolas Usunier</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[7, 9, 5]</td>\n",
       "      <td>[natural language processing]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year         id                                              title  \\\n",
       "0  2017  B1-Hhnslg        Prototypical Networks for Few-shot Learning   \n",
       "1  2017  B1-q5Pqxl  Machine Comprehension Using Match-LSTM and Ans...   \n",
       "2  2017  B16Jem9xe             Learning in Implicit Generative Models   \n",
       "3  2017  B16dGcqlx                    Third Person Imitation Learning   \n",
       "4  2017  B184E5qee  Improving Neural Language Models with a Contin...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A recent approach to few-shot classification c...   \n",
       "1  Machine comprehension of text is an important ...   \n",
       "2  Generative adversarial networks (GANs) provide...   \n",
       "3  Reinforcement learning (RL) makes it possible ...   \n",
       "4  We propose an extension to neural network lang...   \n",
       "\n",
       "                                          authors                  decision  \\\n",
       "0        Jake Snell, Kevin Swersky, Richard Zemel                    Reject   \n",
       "1                       Shuohang Wang, Jing Jiang           Accept (Poster)   \n",
       "2         Shakir Mohamed, Balaji Lakshminarayanan  Invite to Workshop Track   \n",
       "3  Bradly C Stadie, Pieter Abbeel, Ilya Sutskever           Accept (Poster)   \n",
       "4   Edouard Grave, Armand Joulin, Nicolas Usunier           Accept (Poster)   \n",
       "\n",
       "      scores                                      keywords             labels  \n",
       "0  [6, 4, 5]            [deep learning, transfer learning]  transfer learning  \n",
       "1  [6, 6, 7]  [natural language processing, deep learning]    language models  \n",
       "2  [8, 7, 6]                       [unsupervised learning]          unlabeled  \n",
       "3  [6, 5, 6]                                            []          unlabeled  \n",
       "4  [7, 9, 5]                 [natural language processing]    language models  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr[\"labels\"] = labels_iclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-Hhnslg</td>\n",
       "      <td>Prototypical Networks for Few-shot Learning</td>\n",
       "      <td>A recent approach to few-shot classification c...</td>\n",
       "      <td>Jake Snell, Kevin Swersky, Richard Zemel</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>[deep learning, transfer learning]</td>\n",
       "      <td>transfer learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-q5Pqxl</td>\n",
       "      <td>Machine Comprehension Using Match-LSTM and Ans...</td>\n",
       "      <td>Machine comprehension of text is an important ...</td>\n",
       "      <td>Shuohang Wang, Jing Jiang</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 7]</td>\n",
       "      <td>[natural language processing, deep learning]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16Jem9xe</td>\n",
       "      <td>Learning in Implicit Generative Models</td>\n",
       "      <td>Generative adversarial networks (GANs) provide...</td>\n",
       "      <td>Shakir Mohamed, Balaji Lakshminarayanan</td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[8, 7, 6]</td>\n",
       "      <td>[unsupervised learning]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16dGcqlx</td>\n",
       "      <td>Third Person Imitation Learning</td>\n",
       "      <td>Reinforcement learning (RL) makes it possible ...</td>\n",
       "      <td>Bradly C Stadie, Pieter Abbeel, Ilya Sutskever</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>B184E5qee</td>\n",
       "      <td>Improving Neural Language Models with a Contin...</td>\n",
       "      <td>We propose an extension to neural network lang...</td>\n",
       "      <td>Edouard Grave, Armand Joulin, Nicolas Usunier</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[7, 9, 5]</td>\n",
       "      <td>[natural language processing]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year         id                                              title  \\\n",
       "0  2017  B1-Hhnslg        Prototypical Networks for Few-shot Learning   \n",
       "1  2017  B1-q5Pqxl  Machine Comprehension Using Match-LSTM and Ans...   \n",
       "2  2017  B16Jem9xe             Learning in Implicit Generative Models   \n",
       "3  2017  B16dGcqlx                    Third Person Imitation Learning   \n",
       "4  2017  B184E5qee  Improving Neural Language Models with a Contin...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A recent approach to few-shot classification c...   \n",
       "1  Machine comprehension of text is an important ...   \n",
       "2  Generative adversarial networks (GANs) provide...   \n",
       "3  Reinforcement learning (RL) makes it possible ...   \n",
       "4  We propose an extension to neural network lang...   \n",
       "\n",
       "                                          authors                  decision  \\\n",
       "0        Jake Snell, Kevin Swersky, Richard Zemel                    Reject   \n",
       "1                       Shuohang Wang, Jing Jiang           Accept (Poster)   \n",
       "2         Shakir Mohamed, Balaji Lakshminarayanan  Invite to Workshop Track   \n",
       "3  Bradly C Stadie, Pieter Abbeel, Ilya Sutskever           Accept (Poster)   \n",
       "4   Edouard Grave, Armand Joulin, Nicolas Usunier           Accept (Poster)   \n",
       "\n",
       "      scores                                      keywords             labels  \n",
       "0  [6, 4, 5]            [deep learning, transfer learning]  transfer learning  \n",
       "1  [6, 6, 7]  [natural language processing, deep learning]    language models  \n",
       "2  [8, 7, 6]                       [unsupervised learning]          unlabeled  \n",
       "3  [6, 5, 6]                                            []          unlabeled  \n",
       "4  [7, 9, 5]                 [natural language processing]    language models  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4580811588451235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.sum((iclr.labels == \"unlabeled\") & (iclr.year == 2025)) / np.sum(\n",
    "    iclr.year == 2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "iclr.to_parquet(\n",
    "    data_path / \"iclr25v2.parquet\",\n",
    "    index=False,\n",
    "    engine=\"pyarrow\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
